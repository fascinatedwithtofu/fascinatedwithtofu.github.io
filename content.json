{"meta":{"title":"fascinated with tofu","subtitle":null,"description":" ","author":"mo'better tofu","url":"http://www.fascinatedwithtofu.com","root":"/"},"pages":[{"title":"about","date":"2023-01-16T11:09:46.000Z","updated":"2023-01-16T11:09:46.672Z","comments":true,"path":"about/index.html","permalink":"http://www.fascinatedwithtofu.com/about/index.html","excerpt":"","text":""}],"posts":[{"title":"musicxml による楽譜の貼り付けテスト","slug":"music-sheet-share","date":"2023-01-16T13:43:13.000Z","updated":"2023-01-16T14:59:35.043Z","comments":true,"path":"2023/01/16/music-sheet-share/","link":"","permalink":"http://www.fascinatedwithtofu.com/2023/01/16/music-sheet-share/","excerpt":"","text":"はじめにHexo で MuseScore で作成した楽譜や楽譜データを共有する方法を試してみたい。 参考:少し古いが hexo-musicxml-sheetmusic というレンダーを見つけた。公式の手順通りに npm install hexo-musicxml-sheetmusic して、作成した musicxml ファイルは Gist にあげてみた。注意点として Raw ファイルの URL である必要があると推測される。Dropbox や Box の共有リンクではデプロイに失敗した。https://github.com/netbeifeng/hexo-musicxml-sheetmusic SamlpleBb 用に書いた Windows - Chick Corea のリードシート Player なし気づき Player の動作が怪しい。 コーダの繰り返しが消えた。 以上","categories":[{"name":"Music","slug":"Music","permalink":"http://www.fascinatedwithtofu.com/categories/Music/"}],"tags":[{"name":"musicxml","slug":"musicxml","permalink":"http://www.fascinatedwithtofu.com/tags/musicxml/"}]},{"title":"ThinkCentre に Ubuntu Desktop を入れてゲームをする","slug":"ubuntu-desktop-gaming","date":"2023-01-14T09:37:24.000Z","updated":"2023-01-16T07:50:00.082Z","comments":true,"path":"2023/01/14/ubuntu-desktop-gaming/","link":"","permalink":"http://www.fascinatedwithtofu.com/2023/01/14/ubuntu-desktop-gaming/","excerpt":"やったことWindows もあったほうがいいかなと思ってセール時に購入した ThinkCentre M75q-1 Tiny があまり使われていなかったので、Gihyo に触発されて Ubuntu Desktop として利用することにした。起動や動作もサクサクで、Steam や Epic Games も起動でき大満足。いまさら Outerwild と Death Stranding を始めた。","text":"やったことWindows もあったほうがいいかなと思ってセール時に購入した ThinkCentre M75q-1 Tiny があまり使われていなかったので、Gihyo に触発されて Ubuntu Desktop として利用することにした。起動や動作もサクサクで、Steam や Epic Games も起動でき大満足。いまさら Outerwild と Death Stranding を始めた。 機器情報2020年6月に38,720円で購入した第一世代。 Configuration Details● AMD Ryzen 5 Pro 3400GE (3.30GHz, 2MB)● Windows 10 Home 64bit● Windows 10 Home 64bit - 日本語版/英語版選択可能● 8GB PC4-21300 SODIMM● 内蔵グラフィックス● 128GB M.2 2242 NVMe● 内蔵ギガビットイーサネット● IEEE 802.11 ac/a/b/g/n ワイヤレスLAN (WiFi準拠)2x2, Bluetooth (RealTeck製)● 65W ACアダプター● 内部モノラルスピーカー (1.5W)● バーティカルスタンド● ツールレス (オープンシャーシ) その他メモリは余っていた16GBを挿して24GBに。電源は別売135WのACアダプタに切り替えた。 インストールUbuntu LTS 22.04 とした。ローリングリリーススタイルの Arch Linux にも興味があったが簡単に済ませたかったので過去にインストールしたことのあった Ubuntu とした。 Lenovo ThinkCentre Ubuntu などで検索すると公式のインストールガイドがヒットするのでその通りにした。Secure Boot を disabled にして、ブートローダーで USB を一番上にする。minimal オプションにすればよかったなと思ったがこういうリストもあるみたいだ。 参考:Ubuntu 22.04 Linux Setup Guide For ThinkStation P360 Tower, Tiny, Ultra SteamSteam を運営する Valve は Linux サポートにも注力している。製品ページによると SteamOS は Arch ベースだし、Windows ゲームを Linux で動かすための互換レイヤー Proton も開発している。ありがとう。 Linux 向けのクライアントソフトウェアが用意されているため普通にインストールして Steam Play の設定から Enable Steam Play for supported titles にチェックを入れる。 参考: 第626回 UbuntuでもSteamのWindowsゲームを！ Epic Games Store (EPS)こちらは Linux 版はないため、ランチャーを使う。主なものとして Lutris と Heroic Games Launcher があった。両方とも動作したが Death Stranding を安定して動作させられた Heroic を使うことにした。 導入方法は公式の GitHub が参考になった。 参考：GitHub - Heroic-Games-Launcher PS3 コントローラの接続（有線/無線）たまたま家にあったのが PS3 だったので採用した。この記事の通りプラグアンドプレイだった。 以上、Happy Linux Desktop ライフを！","categories":[{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://www.fascinatedwithtofu.com/tags/Ubuntu/"},{"name":"Game","slug":"Game","permalink":"http://www.fascinatedwithtofu.com/tags/Game/"}]},{"title":"Github pages のカスタムドメインを Dozens から Cloudflare に無料移行","slug":"onamaecom-dns-dozens-cloudflare","date":"2019-08-11T15:32:54.000Z","updated":"2023-01-16T07:54:41.810Z","comments":true,"path":"2019/08/12/onamaecom-dns-dozens-cloudflare/","link":"","permalink":"http://www.fascinatedwithtofu.com/2019/08/12/onamaecom-dns-dozens-cloudflare/","excerpt":"はじめにいままで Github Pages をカスタムドメインにするために無料で使っていた DNS サービス Dozens が終了するため、Cloudflare を使って移行してみました。10月31日なんてもうすぐですね。","text":"はじめにいままで Github Pages をカスタムドメインにするために無料で使っていた DNS サービス Dozens が終了するため、Cloudflare を使って移行してみました。10月31日なんてもうすぐですね。 参照全サービス終了のお知らせ ｜ DNSを自由に簡単に。Dozens（ダズンズ） サービス終了までのスケジュール・2019年3月1日（金）新規会員登録・有料プランへのアップグレード受付終了・2019年9月30日（月）コントロールパネル・APIの停止・2019年10月31日（木）DNSサーバーの停止・サービスの完全終了 作業の流れ Cloudflare の設定 お名前.com の設定 確認 作業の流れ１．Cloudflare のアカウント作成とAレコードの登録２．お名前.com のネームサーバーの変更３．確認 Cloudflare の設定わかりやすく書かれているためまさにこのままやってもらえればよいかと思います。参考GitHub Pages + CloudFlare で独自ドメインをSSL化する お名前.com の設定お名前.com Navi にログインして、ドメイン設定 &gt; ネームサーバーの設定 &gt; ネームサーバーの変更 へ進みます。変更したいドメインを選択して 他のネームサーバーを利用 タブを開きます。ネームサーバー情報を入力 の欄に Cloudflare 設定で得られた DNS サーバの名前をすべて入力します。（例：hogehoge.ns.cloudflare.com） 参考【CDN】Cloudflare（クラウドフレア）を利用 確認自分のドメインを dig コマンドで引いたときの Name Server が nxX.dozens.com ではなく hogehoge.ns.cloudflare.com になっていることを確認します。タイミングにもよるかもしれませんが変更して数分以内に切り替わりました。 ) dig fascinatedwithtofu.com +nostats +nocomments ns ; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; fascinatedwithtofu.com +nostats +nocomments ns;; global options: +cmd;fascinatedwithtofu.com. IN NSfascinatedwithtofu.com. 86400 IN NS hoge.ns.cloudflare.com.fascinatedwithtofu.com. 86400 IN NS fuga.ns.cloudflare.com. おしまい","categories":[{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://www.fascinatedwithtofu.com/tags/hexo/"},{"name":"git","slug":"git","permalink":"http://www.fascinatedwithtofu.com/tags/git/"},{"name":"domain","slug":"domain","permalink":"http://www.fascinatedwithtofu.com/tags/domain/"}]},{"title":"家のインターネットの回線速度を speedtest-cli で観測する","slug":"speedtest-cli-splunk","date":"2019-08-08T15:00:00.000Z","updated":"2023-01-16T07:50:15.088Z","comments":true,"path":"2019/08/09/speedtest-cli-splunk/","link":"","permalink":"http://www.fascinatedwithtofu.com/2019/08/09/speedtest-cli-splunk/","excerpt":"はじめに集合住宅のインターネットは利用者が少ない昼間は比較的すいていて、夜間は混雑していることが多いらしい。インターネットが遅いなと感じたときにみんながよく使っている speedtest のコマンドラインツール版があると知り、定期実行して観測してみました。","text":"はじめに集合住宅のインターネットは利用者が少ない昼間は比較的すいていて、夜間は混雑していることが多いらしい。インターネットが遅いなと感じたときにみんながよく使っている speedtest のコマンドラインツール版があると知り、定期実行して観測してみました。 speedtest-cli のインストール 定期実行の設定 splunk (docker) の準備 結果の可視化 speedtest-cli のインストールLinuxでもSpeedtestがしたい（speedtest-cli) を参考にさせてもらいながら、家の mac にインストールしました。git cloneして該当する実行ファイルがspeedtest.pyが実行できればよさそうなので以下のようにしました。試しに実行した結果も少しマスクして載せておきます。 ) # git clone https://github.com/sivel/speedtest-cli Cloning into &#x27;speedtest-cli&#x27;...remote: Enumerating objects: 3, done.remote: Counting objects: 100% (3/3), done.remote: Compressing objects: 100% (3/3), done.remote: Total 1153 (delta 0), reused 1 (delta 0), pack-reused 1150Receiving objects: 100% (1153/1153), 325.70 KiB | 619.00 KiB/s, done.Resolving deltas: 100% (684/684), done.) # cd speedtest-cli/ speedtest-cli) # ./speedtest.py Retrieving speedtest.net configuration...Testing from Softbank BB (x.x.x.x)... Retrieving speedtest.net server list...Selecting best server based on ping...Hosted by GLBB Japan (Tokyo) [6.63 km]: 8.084 m≈sTesting download speed................................................................................Download: 117.30 Mbit/sTesting upload speed................................................................................................Upload: 190.38 Mbit/s その他の要件としては、・インターネット速度の定点観測という趣旨なので、テスト用サーバは固定する(今回は IPA さん 14263 にしてみた)・可視化しやすいように CSV エクスポートする ということで、実行コマンドは以下./speedtest.py --server 14623 --csv &gt;&gt; result.csv CSV エクスポートした場合は以下のような出力となる 14623,IPA CyberLab,Bunkyo,2019-08-11T10:58:53.465639Z,10.824939774573073,5.235,216961778.00509918,167021284.0664986,,x.x.x.x そのため、./speedtest.pyの結果と見比べて、あらかじめ一行目にラベルを入れておきます。名前は適当です。最後から二番目の値が欠けているのも謎です。 id,test_server,city,date,distance,rtt,download,upload,,ip 定期実行の設定30分に一回取得する cron の設定をします。実行は絶対パスで記載する点に注意します。 crontab -l*/30 * * * * python ~/speedtest-cli/speedtest.py --server 14623 --csv &gt;&gt; ~/speedtest-cli/result.csv splunk (docker) の準備CSV をかんたんに時系列データとして可視化する方法として、今回は splunk を利用します。使い捨てのプロセスの感覚で、Docker 上で立てます。ローカルディレクトリを Docker コンテナから参照させたいため、以下の記事を参考にコンテナを起動します。【Docker】Dockerでホストのディレクトリをマウントする docker run -p 8000:8000 -e &quot;SPLUNK_START_ARGS=--accept-license&quot; -e &quot;SPLUNK_PASSWORD=hogehoge&quot; -v ~/speedtest-cli:/opt/splunk/etc splunk/splunk 起動後は http://localhost:8000 にアクセスして、データ参照設定をします。 Settings &gt; DATA &gt; Data inputs Local inputs &gt; File &amp; Directories &gt; Add new ここで Browse から先程マウントしたディレクトリを参照して、result.csv を選択します。その他の設定はそのままでどんどん進んでいけば大丈夫です。 結果の可視化時系列に表示するため timechart 関数を使います。 host=e02bb3812356 | eval download_mb=download/1000000 | timechart avg(download_mb) CSV の場合ダウンロードとアップロードの速度が生の数字 (Bit/sec) で表示されるため、わかりやすくメガ (MBit/sec) に変換するため、eval 関数で1000000で割っています。たまたま hostname で引っ掛けてますが他のインプットデータがないので「*」とかでもよいです。 集合住宅タイプの光フレッツなので夜はなんとなく遅いなと感じていたが、夜間と昼間でそこまで差がなかったのが意外。 (2019/08/15追記)7日間の傾向を span=30min で見てみたら、特に下りは時間帯で傾向がありそう。PM7:00~AM2:30あたりで急速に下り速度が落ちることがわかる。にしても初日だけ500を超えていて、その後最大速度が下り250MB、上り200MBで頭打ちになっているように見える。詐欺・・・","categories":[{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"}],"tags":[{"name":"speedtest-cli","slug":"speedtest-cli","permalink":"http://www.fascinatedwithtofu.com/tags/speedtest-cli/"}]},{"title":"Hexo でひさびさに deploy したらパーミッションエラー","slug":"hexo-permission-denied","date":"2017-08-01T04:22:23.000Z","updated":"2023-01-16T07:34:59.080Z","comments":true,"path":"2017/08/01/hexo-permission-denied/","link":"","permalink":"http://www.fascinatedwithtofu.com/2017/08/01/hexo-permission-denied/","excerpt":"エラー内容hexo d -g すると以下エラーが出た。 Error: Permission denied (publickey).fatal: Could not read from remote repository.","text":"エラー内容hexo d -g すると以下エラーが出た。 Error: Permission denied (publickey).fatal: Could not read from remote repository. 解決方法以下の stack overflow を参考に、_config.yml を変更して解決した。Permission denied (publickey) fatal: Could not read from remote repository. while cloning Git repository deploy: type: git- repo: &#x27;git@github.com:hogehoge/fugafuga.github.io.git&#x27;+ repo: &#x27;https://github.com/hogehoge/fugafuga.github.io.git&#x27; branch: master 以上","categories":[{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://www.fascinatedwithtofu.com/tags/hexo/"}]},{"title":"【雑記】FUJI ROCK FESTIVAL 17 来年快適に過ごすためのカイゼン点まとめ","slug":"fujirock2017-matome","date":"2017-08-01T03:01:15.000Z","updated":"2023-01-16T07:31:01.073Z","comments":true,"path":"2017/08/01/fujirock2017-matome/","link":"","permalink":"http://www.fascinatedwithtofu.com/2017/08/01/fujirock2017-matome/","excerpt":"すっかり更新の手が止まってしまっているうちになぜかはてブの方のアクセス数が急増しておる。先週末はフジロックに行ってきたので、忘れないうちに非音楽面での学びや反省点を残しておきたい。 目的事前準備を時系列に沿って記すことで来年度の行動の目安とする。 結論分かりきっているが、・早起きは三文の徳・早めに準備して損はない","text":"すっかり更新の手が止まってしまっているうちになぜかはてブの方のアクセス数が急増しておる。先週末はフジロックに行ってきたので、忘れないうちに非音楽面での学びや反省点を残しておきたい。 目的事前準備を時系列に沿って記すことで来年度の行動の目安とする。 結論分かりきっているが、・早起きは三文の徳・早めに準備して損はない 宿の手配ここ2年間は2週間前くらいに予約できており、ギリギリなんとか取れているが、本来は GW~6月初旬には押さえておくべき。会場付近から近い順に以下：・会場付近エリア（アーティストやイベント関係者や常連で埋まっているので電話すらしたことない）・田代エリア（バスで10分）・みつまたエリア（バスで20分）・駅前エリア（バスで35分） 「一週間前までは旅行代理店経由でしか受け付けていない」というパターンもあるので、各方面から探すと直前でも見つかる。 チケットの手配・例年行けるか行けないかうだうだして 2週間前に手配・早期に予約すると割引あり 往路の手配・一週間前に確保・MAX とき・越後湯沢からシャトルバス・11−12時頃に会場に着くように移動したが山道が渋滞していたため、もう1時間早くてもよかった・日曜日、ゲートに10時を目指すとさくさく移動できたしトイレや朝ごはんも並ばなかった 荷造り3日前からゆるゆると実施。防水スプレーは持っていっても良かったなと後悔。 雨が必ずといってもいいくらい降るフジロック。今年も Patagonia の Torrentshell Jacket や Keen の Pyrenees にお世話になった。 雨の日はアウトドア系サンダル派とトレッキングブーツ派がいままで主流だと思っていたが、今回非常に目立っていたのが日本野鳥の会バードウォッチング長靴。 5000円程度ながらインソールを入れることで快適なレインライフが送れるもよう。足首の長さが調節可能な点が機能的かつファッショナブル また、濡れることを前提に考えてのスマートウールの靴下は必携。多少水が染みても、汗をかいても、カラッと乾いた気持ちいいやつ。信者レベルで愛用させていただいている。 今年も全面的に電子マネーにお世話になるとのことで、事前に8000円チャージした（一日4千円くらい飲んでしまう想定）。日曜日の夕方に使い切ったので、次年度は多めにチャージが吉。 使える電子マネー一覧iDnanaco楽天EdyWAONQUICpayKitacaSuicaPASMOTOICAmanacaICOCASUGOCAnimocaはやかけん 会期中・各ステージ間の移動は最低20分・会場から各エリアへの無料シャトルバスが25時まで出ている・田代エリアは頑張れば歩けるので、バスは混んでいなそうだった・みつまたの「街道の湯」は会期中は早朝から営業している・雨とわかっている場合、登山ジャケット以外に使い捨て雨合羽などを羽織ってウェアを守ることも考える・時折ウェアを拭いて乾燥させよう・混雑エリア以外であれば折りたたみ傘をさしている人もちらほら（実は禁止されているが、森の中なら怒られたりはしないだろう・・・） 雨宿りスポット・RED MARQUEE・Café de Paris・各種クラブエリア（Palace of Wonder, 苗場食堂）・苗場食堂付近のポカリ、バカルディなど一部のブース・Avaron の太鼓ワークショップ・怪我や体調不良の方は救護エリア・木陰 ＊雨宿りだけせずに音楽を聴きに行こう 復路（月曜日午前）・チケットを事前に買っておくべきだったと反省（発券まで！）・9時起床10時にチェックアウト・12時ごろ駅に着きチケットに30分程度並んだ・月曜日の東京方面のときは指定席は満席・ただし自由席でも一本見送れば確実に座れるし、見送らなくても高崎で非フジロッカーが降りる可能性大 越後湯沢の券売機事情・みどりの窓口（2つ）・えきねっととクレジットカードに対応した発券機（2台）・現金かつ自由席のみ販売可能な発券機（3台）それぞれ行列が分かれているので正しい列を選ぼう","categories":[{"name":"Music","slug":"Music","permalink":"http://www.fascinatedwithtofu.com/categories/Music/"}],"tags":[{"name":"live","slug":"live","permalink":"http://www.fascinatedwithtofu.com/tags/live/"}]},{"title":"【雑記】引っ越しの振り返り〜引っ越しに役立つサービス逆引きリスト 2017年版〜","slug":"hikkoshi-services-2017","date":"2017-04-11T13:09:49.000Z","updated":"2023-01-16T07:34:54.222Z","comments":true,"path":"2017/04/11/hikkoshi-services-2017/","link":"","permalink":"http://www.fascinatedwithtofu.com/2017/04/11/hikkoshi-services-2017/","excerpt":"まだ引っ越しは終わっていないが、無事家が決まり、現在は超絶的断捨離期に突入している。 今回の引っ越しは、これまで幾度となく繰り返してきた引っ越しの経験（おもに過ち）を活かして、なるべく賢く、なるべく身軽に遂行したい！という思いがあり、家探しから家財の処分までいろいろなサービスを積極的に利用していた。 一旦、これまでどんなサービスを活用したのか逆引きリストにしてみたい。","text":"まだ引っ越しは終わっていないが、無事家が決まり、現在は超絶的断捨離期に突入している。 今回の引っ越しは、これまで幾度となく繰り返してきた引っ越しの経験（おもに過ち）を活かして、なるべく賢く、なるべく身軽に遂行したい！という思いがあり、家探しから家財の処分までいろいろなサービスを積極的に利用していた。 一旦、これまでどんなサービスを活用したのか逆引きリストにしてみたい。 家探し物件の比較：Google Spreadsheet x 物件サイトこれは自分の記事への誘導なのでスルーしていただいていいのですが、物件の基本情報の整理はある程度自動化できちゃいますよというお話し。 家探しのための Suumo スクレイピング用スプレッドシート Suumo だけでいいのか？というコメントも頂いたが、実は私も Suumo はそこまでメインに使っていなかった。 下記のようなルーティンワークの中で活用していたのでもしご参考になれば。 ◯家探しのルーティンワーク 住みたいエリアのローカルな不動産屋の中で、更新頻度が高いものをいくつか見つける その不動産屋のホームページをひたすら毎日徘徊（RSSフィード等活用） 気になったものを上記スプレッドシートに貼っていく そのなかでこれだと思うものを契約窓口となる仲介業者に連絡して内見 ＊契約窓口となる仲介業者についても、いくつか連絡してみて親身に迅速に対応してくれそうな人を見つけて、その業者経由でも調べてもらうのは大前提。 ただし、業者の担当者さんも並行して沢山のお客さんの対応をしないといけないので、私一人のために本気で調べ続けてもらうことは難しい。 RSS リーダは Chrome 拡張と同様で Feedly を使っている。 仲介業者選定：人力とフィーリング以下のポストを参考にさせていただいた。 良い物件ではなく良い不動産屋を探した - $shibayu36-&gt;blog; 私は上記を結局4サイクル繰り返して最終的な家を決定した。3月はやはり売り手市場なので時期は考えた方が良い。 家探し余談スクレイピングの表のなかで、初期費用を自動で出してくれる項目を設けた。 どこかで読んだ情報で、初期費用＝家賃の4.5倍になる とあったのだが未検証だった。 =(家賃+管理費)*2+敷金+礼金+仲介手数料（+鍵交換等）トータルコストも気になりますが、初期費用がどれくらいなのかも知りたいですよね。 だいたい家賃の 4.5 ヶ月分程度になると言われています。（ソース不明） 今回の物件にて、まさかの誤差一万円以内だった。余談以上。 引っ越し業者選定引っ越し比較まとめサイト：非推奨見積もりも便利なまとめサイトでやってしまおうと思っていた。 「引越し侍」や「ズバッと（ウェブクルー）」や「価格.com」 が有名だが、ウェブフォームから5分くらいで条件を一通り入力して見積もり申請をしたら最後、平日土日問わず複数の業者から電話が鬼のようにかかってくるためおすすめできない。 たった一度の見積もりで引越し料金を最大50％OFF!!【ズバット 引越し】 何のためにウェブ経由で申込んだのかわからない・・・。 ただここですごいなと思ったのが、さ●いの電話のオペレータがとにかく喋り上手かつ誘導上手。正確な見積もりをするためには家へ見積もりに来てもらうのが一番なのだが、そこのアポ取りへの導き方がとても自然かつ嫌な気がしなかった。 結局、不動産仲介業者の紹介業者と大手とで相見積もりをとって、値段の相場に絶望しつつも感じが良い方を選んだ。参考にならずすみません。 引越し準備不用品処分：ジモティーが最強、売れないものは自治体で粗大ごみは捨てるのであれば自治体にて回収してもらうのが一番安い。 どんな回収業者にも騙されてはいけない。 それにとても爽快感がある。本当だ。そのおこだわりでも「粗大ごみ」の男がこう言っている。 いい顔してますねー、「粗大ゴミ」の男。（清野とおる『その「おこだわり」、俺にもくれよ‼︎』より）#Dモーニング #その「おこだわり」、俺にもくれよ!! https://t.co/CDBuW77tst pic.twitter.com/qBqIWtxNtz&mdash; 清野とおる担当連合 (@oko_aka) 2017年3月9日 ただし、明らかに大きすぎて自治体の粗大ごみ回収でも高くなるものがある。（例：机や棚） また、明らかにまだ使えて買い手がいそうだが、発送や持ち込みするには重すぎる/大きすぎるといった場合もある。（例：電子レンジ、洗濯機、冷蔵庫、ガスコンロ、などなど） そんな時におすすめなのが、ジモティーだ。（伸ばすんですね） 回収で2000円以上かかりそうなサイズの机を、0円出品にして実質2000円浮いた。電子レンジも中古家電屋で買ったものを、−1000円の値段で出品して見事に売れた。快感・・・。 ジモティーは不要な物がすぐ現金化される点も嬉しい。 メルカリやブクマ！は、売れたとしてもお金として手元にくるまでにタイムラグがあるし、振込手数料がかかったりもする。 地元の掲示板「ジモティー」地元でカンタン！フリマよりもお得！JIMOTY, INC.ショッピング無料 ただしここの領域にもメルカリ様のアッテが参入してきている。 メルカリ アッテ-家具も家電も無料!?仲間も見つかる地元のフリマアプリMercari, Inc.ショッピング無料 ####書籍類：メルカリとブクマ！の使い分け？ 古本屋に持ち込むと、重い本を持ち歩くだけでもとても疲れる割に「回収できません」などと言われて0円になってしまうものも多々ある。買取額も二束三文がいいところだ。 メルカリは1000円以下の書籍で、特に漫画類であっても若い世代が定価とほぼ変わらない値段で買ってもらえる印象。 フリマアプリ-メルカリ フリマでかんたんショッピングMercari, Inc.ショッピング無料 一方でブクマ！は比較的堅い書籍が、定価の半値くらいで数多く出品されている。 ブクマ！ - 本をフリマ、オークションで出品できるフリマアプリLabit Inc.ショッピング無料 正直買い手としてはアマゾンで買いがちなのだけど、売り手としてはとてもおいしいマーケットだと思う。 まだ使ったことのない方は試しに何冊か出品してみて欲しい。私は読まなくなった技術書など定価が2000円以上の本を半値で出している。 送料は発送者持ちなので、クリックポストなどを利用するのが安くて簡単だった。 書籍類：大量の本は買取/集荷サービスそれでも大量の本を売りたい場合は出張買取しかないと思う。 最近はとても進化していて、15時までに連絡すればその日のうちにダンボールを届けてくれたりするので、家にいても電話かウェブだけで見積もりから発送まで完了する。 ダンボールはもちろん無料なので安心。 古本、CD、DVD、ゲーム買取のもったいない本舗 ネットオフ（本、CD、ゲーム、DVD等）の買取促進プロモーション 不用品処分のためのアプリ利用シーン決定木感覚的な決定木は以下のようになった。 以上、とりあえずご参考まで。 毎日ダンボールの触り過ぎで手が荒れます。実験用ゴム手袋が恋しい・・・","categories":[{"name":"Other","slug":"Other","permalink":"http://www.fascinatedwithtofu.com/categories/Other/"}],"tags":[{"name":"essay","slug":"essay","permalink":"http://www.fascinatedwithtofu.com/tags/essay/"}]},{"title":"【ライブレポート】Roy Hargrove Quintet＠Blue Note Tokyo","slug":"royhargrove-bluenote-2017","date":"2017-04-03T15:16:48.000Z","updated":"2023-01-16T07:40:42.874Z","comments":true,"path":"2017/04/04/royhargrove-bluenote-2017/","link":"","permalink":"http://www.fascinatedwithtofu.com/2017/04/04/royhargrove-bluenote-2017/","excerpt":"少し経ってしまったが今年もロイ・ハーグローヴがこの時期に来日してくれるとのことで、ジャムセッション会員権限をフルに使ってファーストからセカンドまで通しで聴いてきた。","text":"少し経ってしまったが今年もロイ・ハーグローヴがこの時期に来日してくれるとのことで、ジャムセッション会員権限をフルに使ってファーストからセカンドまで通しで聴いてきた。 思えば2012年、2013年、2014年とブルーノートにてホワイト企業特権()を使って夕方の早い時間から並びコースターの若い番号を競って取ったものである。大学生には負けない。 骨董通りを早歩きで下り会場へ向かい、整理番号が割り振られるまで深めのソファで時間を潰し、（大抵正規の時間より20〜30分程度早く配られた）コースターを受け取ったら南青山七丁目付近を彷徨い買いもしないブティックを覗いたり軽く小腹を満たしたりしてライブに備えた。 今年2月からブルーノート東京のシステムが変わり、当日自由席については予約の電話の時点で整理番号が割り振られるようになったため、もう並ぶ必要がなくなってしまったのは少しさみしい。 メンバーロイ・ハーグローヴ/Roy Hargrove(tp, flh, vo) ジャスティン・ロビンソン/Justin Robinson(sax,fl) 海野雅威/Tadataka Unno(p) アミーン・サリーム/Ameen Saleem(b) クインシー・フィリップス/Quincy Phillips(ds) 公式ページhttp://www.bluenote.co.jp/jp/artists/roy-hargrove/ 概要ROY HARGROVE QUINTET ロイ・ハーグローヴ・クインテット2017 2.28 tue. 3.1 wed., 3.2 thu., 3.3 fri. ◆Blue Note Tokyo〒107-0062東京都港区南青山6-3-16 ライカビル03-5485-0088mon.-fri. 11:00am-9:00pm,sat.,sun.&amp;holiday 11:00am-8:00pm 所感いつになく演奏に切れがあって嬉しくなった。特にセカンドセットでは全体のテンションが高まった状態から一曲目が始まったので、こんな幸運でいいのかなと心のなかで小躍りした。 （写真出典：http://www.bluenote.co.jp/jp/reports/2017/03/01/roy-hargrove-quintet-7.html） 歌あり踊りありという構成はいつもと変わらずの王道エンターテインメント。今回曲調としてはアコースティックに回帰しており純粋にグルーヴィなジャズとソウルフルな歌心を楽しむことができた。 安定のサイドメン ジャスティンもよい仕事ぶりだったように思う。何より、いつもセットリストがその場で決まると言われているライブであったが、何をやらせてもぴったりフロントの息があっていたのは観ていて気持ちいいに決まっている。 海野氏、ハンク・ジョーンズの弟子としてニューヨークで活躍されているとの記事を見たことがあったが、まさかロイのバンドにて凱旋ライブを決めるなんて、素敵だなぁと思った。実際には2016年10月から正式にクインテットに参加していたとのこと。演奏はさりげない連符の精緻さにシダーウッド・ウォルトンのフレイバーを感じたよ。 （写真出典：http://www.bluenote.co.jp/jp/reports/2017/03/01/roy-hargrove-quintet-7.html） 最後、Crazy Race が欲しいなと思っていたところで、テーマが始まって二度目の小躍り事案が発生した。すぐコール＆レスポンスになったのは正直残念だったが、でも嬉しかった。 セットリスト＊調べてわかったもののみ A Shade of JadeBesame MuchoAntiguaLady birdSoothe MeStrasbourg-St. DenisThe ThemeCrazy Race ファーストセットで印象に残っているのは Lady bird 。ボーカルに始まりアルト、ピアノの安定したソロを経てハーマンミュートでのソロと続いた。いろんなジャイアンツたちの面影を感じさせるいい内容。 さ、届いた JTNC 4 読んで寝ます。","categories":[{"name":"Music","slug":"Music","permalink":"http://www.fascinatedwithtofu.com/categories/Music/"}],"tags":[{"name":"live","slug":"live","permalink":"http://www.fascinatedwithtofu.com/tags/live/"}]},{"title":"【ライブレポート】Kasper Tranberg J Quartet@新宿 Pit Inn","slug":"live-kasper-pitinn","date":"2017-03-21T14:04:17.000Z","updated":"2023-01-16T07:36:41.658Z","comments":true,"path":"2017/03/21/live-kasper-pitinn/","link":"","permalink":"http://www.fascinatedwithtofu.com/2017/03/21/live-kasper-pitinn/","excerpt":"デンマーク出身キャスパー・トランバーグなる人のことは全く知らなかったが、兎にも角にもピットインにて花金をキメてきた。","text":"デンマーク出身キャスパー・トランバーグなる人のことは全く知らなかったが、兎にも角にもピットインにて花金をキメてきた。 Youtube などは一通りチェックしたが誰にも似ておらず、難しそうな演奏が多かったため空いているだろうと思っていたら（失礼っ）、20時ちょうどにフロアに入るとほとんど80％程度の座席がすでに埋まり、観客達はみなショウが始まるのをじっと待っていた。 いそいそと席にありつきコートや荷物を置いたあたりで演奏がファーストセットが始まった。 北欧系？フリージャズ？正直実験的でいつ息をついていいのかわからないような5人の演奏は、ちょうど前の週に大いに楽しんだ開放的でグルーヴィなロイ・ハーグローヴの音楽とは実に対象的だった。 メンバーキャスパー・トランバーグ（Cor,Tp）南 博（P）水谷浩章（B）外山 明（Ds）ゲスト：ラーシュ・グリーヴ（Sax） 南氏とキャスパー氏の交友関係が深いもよう。 概要3/10（金）Kasper Tranberg J Quartet開場PM7:30 開演PM8:00 \\3,000(1DRINK付) ◆Pit InnTEL:03-3354-20242-12-4 ACCORD BLDG. B1Shinjuku shinjuku-ku Tokyo JAPAN〒160-0022 セットリスト1st Set・・・45分程度切れ目なく演目不明2nd Set・・・45程度切れ目なく演目不明 サボっていたわけではありません。 所感フロントの Kasper と Lars が出す不思議な音を楽しんだ2時間半だった。 音楽的には北欧風というとざっくりしすぎだが、おそらくイメージしてもらえるであろう緊張を強いられるような抑圧された調子が各セットにおいてそれぞれ続いた。 Kasper は Kenny Wheeler のような鋭く繊細な音色でトランペットやコルネットの持つ金属的な音色を充分に披露してくれていた。速いパッセージを吹くときなどは本当に楽器の演奏能力が高いのだとわかった。 Lars はテナーやクラリネットをディジュリドゥのようなプリミティブな楽器にして長い場面を作り出していたのが印象的だった。雑音や環境音にも近い音だが不快なサウンドは一切なかった。 全然別のグループだが↓のような音。https://www.youtube.com/watch?v=zUb3Kt7E5T8 水谷氏は相変わらず無くてはならない存在感を深く静かに湛えていた。静かすぎて曲と一体化しているように見えた。 さいごに今回のライブで、今年に入ってから10公演くらいは聴きにこれていることになる。まだまだ沢山ライブへ行きたい。 今回も中華を食べてから臨んだ。酸辣湯。Sun Ra Tanḡ","categories":[{"name":"Music","slug":"Music","permalink":"http://www.fascinatedwithtofu.com/categories/Music/"}],"tags":[{"name":"live","slug":"live","permalink":"http://www.fascinatedwithtofu.com/tags/live/"}]},{"title":"GAS で公開中/予定の映画情報をスクレイピングして Slack へ定期的にポストする","slug":"gas-slack-movie-scraping","date":"2017-03-16T06:46:58.000Z","updated":"2023-01-16T07:30:06.399Z","comments":true,"path":"2017/03/16/gas-slack-movie-scraping/","link":"","permalink":"http://www.fascinatedwithtofu.com/2017/03/16/gas-slack-movie-scraping/","excerpt":"プライベート用スマホにしている Android のパフォーマンスがどんどん劣化しており、結果 Line があまり使いこなせず、家庭内（＝個人向け） Slack を導入したいと思いはじめいろいろ調べている。 そうするうちに Twitter Bot の Cron Job としてのみ使っていた（放置していた） Google App Script 環境との相性が良さそうとだなとわかり、何か自分向けサービスめいたものを画策している。 服でも道具でもなんでも、カスタムできるという点が愛着につながると思う。 まずは簡単な定期実行ものを作ってみた。","text":"プライベート用スマホにしている Android のパフォーマンスがどんどん劣化しており、結果 Line があまり使いこなせず、家庭内（＝個人向け） Slack を導入したいと思いはじめいろいろ調べている。 そうするうちに Twitter Bot の Cron Job としてのみ使っていた（放置していた） Google App Script 環境との相性が良さそうとだなとわかり、何か自分向けサービスめいたものを画策している。 服でも道具でもなんでも、カスタムできるという点が愛着につながると思う。 まずは簡単な定期実行ものを作ってみた。 参考たち主にこちらを活用させていただいた。スプレッドシートで管理しているKPIをSlackに自動投稿するGoogle Apps Scriptを作ってみた 市井に根付く Slack家族間の連絡手段をLINEからSlackにしてみた話（追記あり） パンチの効いた…Slackがカップル専用アプリだった件 尊敬割と本気で家庭用Slack Botを作ってみた 成果物イメージSlack 内のあるチャネルに対して、時間を決めて映画タイトル＋詳細URLを流し込むことができた。 ＊コンマは消せなかった・・・orz 以下やったことを羅列していきます。 GAS サンプルvar slack = &#123; postUrl: &#x27;https://slack.com/api/chat.postMessage&#x27;, token: &#x27;xoxp-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&#x27;, channelId: &quot;hogehoge&quot;, userName: &quot;映画bot&quot;, icon_Emoji: &quot;:whale:&quot;, // テキスト量が多いと表示されなかったりする・・・&#125;var postMessage = function(text) &#123; UrlFetchApp.fetch(slack[&quot;postUrl&quot;], &#123; &quot;method&quot; : &quot;post&quot;, &quot;payload&quot; : &#123; token: slack[&quot;token&quot;], channel: slack[&quot;channelId&quot;], username: slack[&quot;userName&quot;], icon_emoji: slack[&quot;icon_Emoji&quot;], text: text &#125; &#125;);&#125;function myFunction() &#123; var ss = SpreadsheetApp.getActiveSpreadsheet(); var sheet = ss.getSheets()[0]; var titlenow = sheet.getSheetValues(4,2,20,4); var titleupcoming = sheet.getSheetValues(4,7,20,6);// 抜き出したいエクセルの範囲指定方法。詳しくは https://developers.google.com/apps-script/reference/spreadsheet/spreadsheet#getSheetValues(Integer,Integer,Integer,Integer) postMessage(&quot;いま公開中の映画:movie_camera:は&quot;+ String.fromCharCode(10) + titlenow + String.fromCharCode(10) + &quot;だよ:movie_camera:&quot;); postMessage(&quot;近日公開予定の映画:movie_camera:は&quot;+ String.fromCharCode(10) + titleupcoming + String.fromCharCode(10) + &quot;:movie_camera:以上&quot;); &#125; GAS 作成の前提条件元となる Google Spreadsheet を作成し、次に解説している「スプレッドシートサンプル」のような情報を記載しておく。 次に、ツール &gt; スクリプトエディタから GAS 作成画面へ。 スプレッドシートの解説 使った関数はIMPORTXMLとCONCATENATEの２つ。 タイトル=IMPORTXML(https://filmarks.com/movies/showing/now, &quot;//*[@class=&#39;c-movie-item&#39;]/h3/a&quot;) 注意・実際にはキャプチャの通り URL および XPATH は別セルに入れておいて、関数の中身は (B2, D2) といったシンプル設計・セミコロンとコロンが重複しないよう注意 映画詳細リンク=CONCATENATE(&quot;https://filmarks.com&quot;, IMPORTXML(https://filmarks.com/movies/showing/now, &quot;//*[@class=&#39;c-movie-item&#39;]/h3/a/@href&quot;))` __注意 __・「タイトル」同様関数の中身は直打ちしていない。・一旦 F 列に相対リンク （/movies/62215）などを生成し、その後CONCATENATE関数で合体させている Slack Token 情報取得事前に Your app を作成しておく必要あり。https://api.slack.com/apps 新し目の記事でないと、Slack 側の GUI が変わっており戸惑った。Slack APIのTokenの取得・場所 Features &gt; OAuth &amp; Permissions というタブで何を許可したら最小限か正直わからなかったが、Post するという目的からしてOTHER &gt; Post to specific channels in Slack. &gt; incoming-webhookかなと思ってそれ以外は追加していない。 Features Incoming Webhooks でも Activate してある。 Redirect URLも空欄のままでよかった。 Slack チャネル情報取得プライベートのチャネルhttps://api.slack.com/methods/groups.list/test パブリックのチャネルhttps://api.slack.com/methods/channels.list/test &quot;id&quot;: &quot;HOGEHOGE&quot;,という情報だけが必要。 仕上げトリガーの設定（GAS における Cron 的なもの）を作成。N時間おきだったり、ある週のある時間だったり（ただし1時間おきに設定しても2~30分のずれは当たり前）。","categories":[{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"}],"tags":[{"name":"scraping","slug":"scraping","permalink":"http://www.fascinatedwithtofu.com/tags/scraping/"},{"name":"slack","slug":"slack","permalink":"http://www.fascinatedwithtofu.com/tags/slack/"},{"name":"gas","slug":"gas","permalink":"http://www.fascinatedwithtofu.com/tags/gas/"},{"name":"movie","slug":"movie","permalink":"http://www.fascinatedwithtofu.com/tags/movie/"}]},{"title":"【読書】山崎元のお金入門本二冊を読んだ感想","slug":"money-book-for-beginners","date":"2017-03-16T06:43:12.000Z","updated":"2023-01-16T07:39:11.951Z","comments":true,"path":"2017/03/16/money-book-for-beginners/","link":"","permalink":"http://www.fascinatedwithtofu.com/2017/03/16/money-book-for-beginners/","excerpt":"会社の先輩から、「素人サラリーマンが投資やお金のことに興味を持ち始めた時に、先ず読むべき」と進められた2冊。一冊は通勤時間、もう一冊は長風呂中に読み切った。 要点をおさえたあとの行動のほうが重要なので、さくっと Kindle 版で流しながら読むのがいいと思う。","text":"会社の先輩から、「素人サラリーマンが投資やお金のことに興味を持ち始めた時に、先ず読むべき」と進められた2冊。一冊は通勤時間、もう一冊は長風呂中に読み切った。 要点をおさえたあとの行動のほうが重要なので、さくっと Kindle 版で流しながら読むのがいいと思う。 一冊目：難しいことはわかりませんが、お金の増やし方を教えてください！2014年に「ウルフオブウォールストリート」を観て以来、・「マネーショート 華麗なる大逆転」(2016)・「インサイドジョブ 世界不況の知られざる真実」(2010) (Hulu にてたまたま発掘)など米国金融の悪い側面を題材とした映画を観ていたが、およそそのままのフィーリングで読めた()。 *いまみたら上3タイトルのうちストリーミングサービスで閲覧できそうなものは dTV にてウルフオブウォールストリートのみ 感想私が理解できた論旨は実に単純で、 ・投資しましょう・大手証券口座は手数料が高いのでネットバンクで始めましょう・インデックス連動型の投資信託にしましょう 以上。 結果として、今まで株主優待重視型だったがちゃんとインデックス連動型を二種類買い始めた。アベノミクスのお陰か微増中。 二冊目：お金が貯まるのは、どっち!?概ね先に読んだ本と論旨は同じだが、家計簿の内訳を割合で把握する点が新しかった。 マネーフォワードとかで皆様もうされてることかも。 感想個人的に書かれている中で納得できない点としては、 ・持ち家に関しては肯定&amp;運用派・保険加入は必須との考え方の2点。 何故そう思うかはまた整理したい。","categories":[{"name":"Book","slug":"Book","permalink":"http://www.fascinatedwithtofu.com/categories/Book/"}],"tags":[{"name":"money","slug":"money","permalink":"http://www.fascinatedwithtofu.com/tags/money/"}]},{"title":"3分で Mac OS X に squid プロキシをたてる","slug":"squid-on-mac-osx","date":"2017-03-16T06:35:19.000Z","updated":"2023-01-16T07:50:13.469Z","comments":true,"path":"2017/03/16/squid-on-mac-osx/","link":"","permalink":"http://www.fascinatedwithtofu.com/2017/03/16/squid-on-mac-osx/","excerpt":"不定期にローカルネットワーク内で作業する機会に恵まれる。そうしたとき大抵 yum や online license 認証的なことが必要となり、なし崩し的に「そうだ、Squid たてよう」となる。 最新の brew はとても便利で、すぐにおれおれ proxy が立てられたのでメモがてらどうぞ。","text":"不定期にローカルネットワーク内で作業する機会に恵まれる。そうしたとき大抵 yum や online license 認証的なことが必要となり、なし崩し的に「そうだ、Squid たてよう」となる。 最新の brew はとても便利で、すぐにおれおれ proxy が立てられたのでメモがてらどうぞ。 ＊日本語の技術ブログをいくつか参考にさせてもらったのだが、開始・停止コマンドだけ新しくなっていそうなのでそこだけ真新しさがある記事。 前提条件・Mac OS X 10.11.6 （わたしが）・homebrew 環境あり インストールと post install メッセージbrew install squid Updating Homebrew...&lt;snip&gt;To have launchd start squid now and restart at login: brew services start squid Or, if you don&#x27;t want/need a background service you can just run: squid &lt;snip&gt; 設定ファイルの編集おそらく大半の人が触らなくていいのでは？設定変更したい場合、参照を見ていただければそちらの方が詳しい。 私の場合は、以下のみ追記した。 vi /usr/local/etc/squid.conf acl localnet src X.X.X.X/YY &lt;= 今回たまたまイレギュラーな IP レンジがローカルネットに存在したため追記 サービス開始上のメッセージに従おう。 brew services start squid ただし、メッセージにあるような squid コマンドは使えず。 ここで、下に貼ったbrew services を読むと、 [sudo] brew services run formula|–all Run the service formula without starting at login (or boot). とあるので、正確には一時的にサービス開始コマンドbrew services run squidサービス自動起動コマンドが以下brew services start squidだと思われた。 紛らわしいことに両方とも開始語のメッセージは同じだった。 brew services start squid==&gt; Successfully started `squid` (label: homebrew.mxcl.squid) brew services run squid==&gt; Successfully started `squid` (label: homebrew.mxcl.squid) サービス停止こちらは共通のよう。 brew services stop squid おまけ：brew services command初めて使った。 #brew servicesbrew services Easily start and stop formulae via launchctl Integrates Homebrew formulae with OS X&#x27;s launchctl manager. Services can be added to either /Library/LaunchDaemons or ~/Library/LaunchAgents. Basically, items in /Library/LaunchDaemons are started at boot, while those in ~/Library/LaunchAgents are started at login. When started with sudo, it operates on /Library/LaunchDaemons; otherwise, it operates on ~/Library/LaunchAgents. On start the plist file is generated and written to a Tempfile, and then copied to the launch path (existing plists are overwritten). [sudo] brew services list List all running services for the current user (or root) [sudo] brew services run formula|--all Run the service formula without starting at login (or boot). [sudo] brew services start formula|--all Install and start the service formula at login (or boot). [sudo] brew services stop formula|--all Stop the service formula after it was launched at login (or boot). [sudo] brew services restart formula|--all Stop (if necessary), install and start the service formula at login (or boot). [sudo] brew services cleanup Remove all unused services. 例えば自動起動設定しているサービスのリストは以下。brew services list brew services listName Status User Plistdnsmasq stopped squid stopped 参照http://qiita.com/kmats@github/items/8a41c942e079c7a95919 http://qiita.com/mtakayuki/items/6869fa4760afc9a659e9","categories":[{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"}],"tags":[{"name":"squid","slug":"squid","permalink":"http://www.fascinatedwithtofu.com/tags/squid/"}]},{"title":"Apple の Auto Link Maker を Hexo ブログに追加してみる","slug":"apple-autolinkmaker-hexo","date":"2017-02-20T13:57:44.000Z","updated":"2023-01-16T07:53:33.420Z","comments":true,"path":"2017/02/20/apple-autolinkmaker-hexo/","link":"","permalink":"http://www.fascinatedwithtofu.com/2017/02/20/apple-autolinkmaker-hexo/","excerpt":"前回の記事と同じ要領で、Hexo Blog のほうにも同じく Auto Link Maker を埋め込みたいと思います。JavaScript を生成してクリップボードにコピーしておくところまでは前回と同じですので割愛します。","text":"前回の記事と同じ要領で、Hexo Blog のほうにも同じく Auto Link Maker を埋め込みたいと思います。JavaScript を生成してクリップボードにコピーしておくところまでは前回と同じですので割愛します。 Hexo 側の設定Amazon Publisher Studio のときと同じく themes/landscape/layout/_partial/footer.ejs の中に一行追加します。 vi themes/landscape/layout/_partial/footer.ejs &lt;footer id=&quot;footer&quot;&gt; &lt;% if (theme.sidebar === &#x27;bottom&#x27;)&#123; %&gt; &lt;%- partial(&#x27;_partial/sidebar&#x27;) %&gt; &lt;% &#125; %&gt; &lt;div class=&quot;outer&quot;&gt; &lt;div id=&quot;footer-info&quot; class=&quot;inner&quot;&gt; &amp;copy; &lt;%= date(new Date(), &#x27;YYYY&#x27;) %&gt; &lt;%= config.author || config.title %&gt;&lt;br&gt; &lt;%= __(&#x27;powered_by&#x27;) %&gt; &lt;a href=&quot;http://hexo.io/&quot; target=&quot;_blank&quot;&gt;Hexo&lt;/a&gt;&lt;!-- Start of Amazon Publisher Studio Loader --&gt; &lt;script&gt; window.amznpubstudioTag = &quot;hogehoge-22&quot;; &lt;/script&gt; &lt;!-- Do not modify the following code ! --&gt; &lt;script async=&quot;true&quot; type=&quot;text/javascript&quot; src=&quot;http://ps-jp.amazon-adsystem.com/domains/hogehoge-22_eb08f220-59e2-4a2d-b8d8-186be420abee.js&quot; charset=&quot;UTF-8&quot;&gt;&lt;/script&gt; &lt;!-- End of Amazon Publisher Studio Loader --&gt;&lt;script type=&#x27;text/javascript&#x27;&gt;var _merchantSettings=_merchantSettings || [];_merchantSettings.push([&#x27;AT&#x27;, &#x27;hogehoge&#x27;]);(function()&#123;var autolink=document.createElement(&#x27;script&#x27;);autolink.type=&#x27;text/javascript&#x27;;autolink.async=true; autolink.src= (&#x27;https:&#x27; == document.location.protocol) ? &#x27;https://autolinkmaker.itunes.apple.com/js/itunes_autolinkmaker.js&#x27; : &#x27;http://autolinkmaker.itunes.apple.com/js/itunes_autolinkmaker.js&#x27;;var s=document.getElementsByTagName(&#x27;script&#x27;)[0];s.parentNode.insertBefore(autolink, s);&#125;)();&lt;/script&gt; &lt;/div&gt; &lt;/div&gt;&lt;/footer&gt; hexo clean, hexo d -g したら完了です。 関連する記事www.fascinatedwithtofu.com","categories":[{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://www.fascinatedwithtofu.com/tags/hexo/"},{"name":"apple","slug":"apple","permalink":"http://www.fascinatedwithtofu.com/tags/apple/"}]},{"title":"家探しのための Suumo スクレイピング用スプレッドシート","slug":"suumo-scraping","date":"2017-02-19T12:39:54.000Z","updated":"2023-01-16T07:50:08.657Z","comments":true,"path":"2017/02/19/suumo-scraping/","link":"","permalink":"http://www.fascinatedwithtofu.com/2017/02/19/suumo-scraping/","excerpt":"丁度探しているんですが、家探しって情報戦です。いろいろ情報がインターネットに落ちてはいるものの、なかなか人手で一つにまとめて比較検討するのは大変です。そんなときこそウェブスクレイピングの出番です。（いろしろ写真みて表作って、というのも充分楽しい作業ではあるんですけどね。） 物件の URL を入れると基本情報＋2年住んだ場合のトータルコスト概算を出してくれるスプレッドシートを作成しました。（サンプルあり）","text":"丁度探しているんですが、家探しって情報戦です。いろいろ情報がインターネットに落ちてはいるものの、なかなか人手で一つにまとめて比較検討するのは大変です。そんなときこそウェブスクレイピングの出番です。（いろしろ写真みて表作って、というのも充分楽しい作業ではあるんですけどね。） 物件の URL を入れると基本情報＋2年住んだ場合のトータルコスト概算を出してくれるスプレッドシートを作成しました。（サンプルあり） スクレイピングについては以前にも書いたので参考までに以下もどうぞ Google 先生に聞いても意外とわからなかったウェブスクレイピング基礎編 Google 先生に聞いても意外とわからなかったウェブスクレイピング実践編1 Google 先生に聞いても意外とわからなかったウェブスクレイピング実践編2 ###参考 ほとんど前者を参考にさせていただきました。後者はクローラとセットで検索するところから指定されており、すごいなぁと。 Google Spreadsheetで効率的に物件を探す 【技術】エンジニアの家探しについて IMPORTXML - Docs editors Help REGEXREPLACE - ドキュメント エディタ ヘルプ ###前提A3にURLを入れるとします。単位は 万円とします。更新料を1ヶ月分と仮定しています。トータルコスト等の計算式はご自由に変更ください。 以下の Xpath は上記のウェブスクレイピング記事と同様に Chrome で表示した際の Developer Tools から右クリックコピーにて採取しています。ただし Google スプレッドシート側の仕様で、Xpath 自体を二重引用符で囲む必要がありますのでここだけ書き直しが必要です。 下のリストは、使用できるすべての関数をカテゴリ別に示しています。関数を使用する際は、セル参照や列参照でないアルファベット文字で構成される関数要素はすべて、二重引用符で囲むようにしてください。 ###デメリット物件の掲載期間が終わったら、スクレイピングしてきた情報ごと消えます。あとで見返したりしたい場合は、値のみコピー/バックアップする運用をおすすめします。 ###家賃=REGEXREPLACE(IMPORTXML(A3,&quot;//*[@id=&#39;contents&#39;]/div[1]/div[2]/div[1]/table/tbody/tr/td[1]/div/div[1]/span&quot;), &quot;万円&quot;, &quot;&quot;) ###管理費=REGEXREPLACE(REGEXREPLACE(IMPORTXML(A3, &quot;//*[@id=&#39;contents&#39;]/div[1]/div[2]/div[1]/table/tbody/tr/td[1]/div/div[2]/span&quot;), &quot;管理費・共益費 &quot;, &quot;&quot;), &quot;円&quot;, &quot;&quot;)/10000 ###敷金=REGEXREPLACE(IMPORTXML(A3,&quot;//*[@id=&#39;contents&#39;]/div[1]/div[2]/div[1]/table/tbody/tr/td[2]/div/div[1]/span[2]&quot;), &quot;万円&quot;, &quot;&quot;) ###礼金=REGEXREPLACE(IMPORTXML(A3,&quot;//*[@id=&#39;contents&#39;]/div[1]/div[2]/div[1]/table/tbody/tr/td[2]/div/div[2]/span[2]&quot;), &quot;万円&quot;, &quot;&quot;) ###築年数=IMPORTXML(A3, &quot;//*[@id=&#39;contents&#39;]/div[1]/div[2]/div[1]/table/tbody/tr/td[4]/div/div[2]&quot;) ###面積=REGEXREPLACE(IMPORTXML(A3, &quot;//*[@id=&#39;contents&#39;]/div[1]/div[2]/div[1]/table/tbody/tr/td[3]/div/div[2]/text()&quot;), &quot;m&quot;, &quot;&quot;) ###仲介手数料=家賃/2+1.5どこかのサイトで読んだざっくり式 ###更新料1ヶ月分の家賃想定 ###鍵交換等すみませんスクレイピングできなかったので、目 grep してください。保険, クリーニング代 etc… ###トータルコスト（2年）=(家賃+管理費)*24+敷金+礼金+仲介手数料（+鍵交換等） ###初期費用=(家賃+管理費)*2+敷金+礼金+仲介手数料（+鍵交換等）トータルコストも気になりますが、初期費用がどれくらいなのかも知りたいですよね。だいたい家賃の 4.5 ヶ月分程度になると言われています。（ソース不明） ###サンプル注意）4行目だけ編集可能になっています。ご自分のスプレッドシートでいろいろ試してみてください。 サンプルの Google Spread Sheet こんなのなくても元のDBにアクセスできたら、早いんだらうなぁ。","categories":[{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"}],"tags":[{"name":"scraping","slug":"scraping","permalink":"http://www.fascinatedwithtofu.com/tags/scraping/"}]},{"title":"【初学者向け】自動車/車載ネットワーク関連サイバーセキュリティ まとめ（随時更新）","slug":"car-can-security","date":"2017-02-17T08:52:04.000Z","updated":"2023-01-16T07:28:41.996Z","comments":true,"path":"2017/02/17/car-can-security/","link":"","permalink":"http://www.fascinatedwithtofu.com/2017/02/17/car-can-security/","excerpt":"半分仕事、半分趣味のまとめです。基本的にリンクを貼っていくだけの場所ですが随時整備していく予定です。 日本の団体による自動車セキュリティに関する講演資料2020年の自動車社会とセキュリティIPAによる2014年の内容で、日本が進んでいるというメッセージがあり、奢りが見える内容です。。 IoTのセキュリティ～ハッカーによる攻撃の現状と対策ポイント～2015年のJPNIC総会の内容で車に限らないハッキング事例を紹介しています。","text":"半分仕事、半分趣味のまとめです。基本的にリンクを貼っていくだけの場所ですが随時整備していく予定です。 日本の団体による自動車セキュリティに関する講演資料2020年の自動車社会とセキュリティIPAによる2014年の内容で、日本が進んでいるというメッセージがあり、奢りが見える内容です。。 IoTのセキュリティ～ハッカーによる攻撃の現状と対策ポイント～2015年のJPNIC総会の内容で車に限らないハッキング事例を紹介しています。 自動車の情報セキュリティの“ものさし”を作る (1/3)ものさし＝標準ということかと理解しました。 日本では、日本自動車工業会（JAMA）が業界方針づくりを、日本自動車技術会（JSAE）が標準や規格作りを、JasParが自動車に実装するための標準技術や評価方法を策定するという役割分担になっている。 JASPARの概要第3回ディペンダビリティに関する定期意見交換会 資料 一般社団法人*JASPARは２００４年９月に、高度化・複雑化する車載電子制御システムのソフトウェアやネットワークの標準化および共通利用による、開発の効率化と高信頼性確保を目指し設立されました。自動車メーカー、電装品メーカー、半導体メーカー、ソフトウェア開発の各業種から技術者が参画し、海外・国内の関連団体との協調の下、車載ＬＡＮ、ソフトウェア、マイコンおよび情報系領域における標準化を推進しています。 JAMAGAZINE業界方針づくりを担う団体JAMA（日本自動車工業会）が発行する雑誌。リンクは2016年4月のもの。まるごと読めるのはありがたいですね。 運転支援通信システムに関するセキュリティガイドライン（ITS FORUM RC‐009 第1.2版）V2X Vehicle to X つまり車と何かの通信に関する規格IEEE1609.2についてのガイドラインを含んでいます。 自動車関連企業による自動車セキュリティに関する講演資料つながるクルマのセーフティ&amp;セキュリティDENSOによる2015年の内容です。こちらも標準化について国内外動向の整理をしています。 セキュリティ企業による自動車セキュリティレポートFFRI が非常に精力的にレポートを出していました。 セキュリティカンファレンスから見る自動車セキュリティ（PDF/Jpn） 自動車の脆弱性事例とCVSS v3による評価 STRIDEの変化形とセキュリティ要件で導き出す脅威分析手法 セキュリティイベントにおける自動車ハッキング(PEN)TESTING VEHICLES WITH CANTOOLS Black Hat USA 2015：ジープのハッキングの全容が明らかに ドライバーに衝撃：走行中のジープの乗っ取りに成功 自動車ハッキングエミューレーションツールcantoolsオープンソースのcantools の libcandbcで、.dbcファイルの読み込み いま手に入りそうで初学者でも読めそうな参考書（随時更新）もう一冊手頃そうなものがありましたが、在庫切れでした。DENSOの方が書かれた本は上級者向けみたいですね。","categories":[{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"}],"tags":[{"name":"IoT","slug":"IoT","permalink":"http://www.fascinatedwithtofu.com/tags/IoT/"},{"name":"security","slug":"security","permalink":"http://www.fascinatedwithtofu.com/tags/security/"}]},{"title":"Apple の Auto Link Maker をはてぶに追加してみる(試行錯誤中)","slug":"apple-autolinkmaker-hatebu","date":"2017-02-17T05:33:34.000Z","updated":"2023-01-16T07:26:30.943Z","comments":true,"path":"2017/02/17/apple-autolinkmaker-hatebu/","link":"","permalink":"http://www.fascinatedwithtofu.com/2017/02/17/apple-autolinkmaker-hatebu/","excerpt":"はじめに前回 - Hexo / はてなブログに Amazon Publisher Studio を埋め込んでみたら想像以上に便利に引き続き Apple アフィリエイトにも自動でアップルのリンクをアフィリエイト仕様にしてくれるスクリプトがあることを知ったので、まずはてぶに導入しました。 メリットApple Affiliate でリンクを作成されたことが有る方はおわかりかもしれませんが、 リンク作成画面へ行く 商品を検索する リンクをコピーするというステップは意外に面倒です。このスクリプトがあれば、iTunes や ブラウザで閲覧しているものを、右クリックコピーではてぶに書けば、あとは自動的にあなたの Affiliate Token を紐付けてくれます。 設定方法方法は本家を読むと、Amazon Publisher Studio とまったく同じ要領です。 How to InstallAfter going to Auto Link Maker and inserting your affiliate token, simply copy the javascript code and place it into the footer on your blog or website. The code will not function properly if it is added to the header.The following are examples on how to add the Auto Link Maker code and may not cover your same configuration. You are responsible for making sure that you add the code correctly to your website or blog. （大意）フッタにスクリプトをコピペしろ。","text":"はじめに前回 - Hexo / はてなブログに Amazon Publisher Studio を埋め込んでみたら想像以上に便利に引き続き Apple アフィリエイトにも自動でアップルのリンクをアフィリエイト仕様にしてくれるスクリプトがあることを知ったので、まずはてぶに導入しました。 メリットApple Affiliate でリンクを作成されたことが有る方はおわかりかもしれませんが、 リンク作成画面へ行く 商品を検索する リンクをコピーするというステップは意外に面倒です。このスクリプトがあれば、iTunes や ブラウザで閲覧しているものを、右クリックコピーではてぶに書けば、あとは自動的にあなたの Affiliate Token を紐付けてくれます。 設定方法方法は本家を読むと、Amazon Publisher Studio とまったく同じ要領です。 How to InstallAfter going to Auto Link Maker and inserting your affiliate token, simply copy the javascript code and place it into the footer on your blog or website. The code will not function properly if it is added to the header.The following are examples on how to add the Auto Link Maker code and may not cover your same configuration. You are responsible for making sure that you add the code correctly to your website or blog. （大意）フッタにスクリプトをコピペしろ。 以下やりかたです。 ステップ1 Auto Link Maker へアクセス*Apple Affiliate アカウントを作成する部分は割愛します。こちらなどが丁寧に紹介されています。 管理画面にログインしてツールへ飛びます。左下のAuto Link Maker にアクセスする へ進みます。 ステップ2 JavaScript の作成ログインした状態で上のリンクへ進むと、あなたのAffiliate Token が埋め込まれた状態の JavaScript が生成されています。こちらをクリップボードへコピーします。（下の国マークは、画面の表示言語ですのであまり関係ないと思われます） ステップ3 はてぶの設定変更はてぶの管理画面のタブから、デザイン＞カスタマイズ＞フッタへと進みます。 私の場合、一行目に Amazon Publisher Studio のスクリプトが書かれていますので、この下の行に、さきほどクリップボードへコピーしたスクリプトを貼り付けます。 こんな形になると思います。 &lt;!-- Start of Amazon Publisher Studio Loader --&gt; ... （中略）... &lt;script&gt; &lt;/script&gt; &lt;!-- Amazon のスクリプト --&gt;&lt;script type=&#x27;text/javascript&#x27;&gt;var _merchantSettings=_merchantSettings || ... （中略）... &lt;/script&gt; &lt;!-- 今回追加する Apple のスクリプト --&gt; 最後に、変更を保存して完了です。 確認ブラウザから右クリックでコピーします。大好きな Podcast のひとつ、Piano Jazz Shorts by NPRです。 Piano Jazz Shorts by NPR コピーしたときの URL は https://itunes.apple.com/jp/podcast/piano-jazz-shorts/id121493685?mt=2# でしたが、ブログとして見ると見事に私の Token が自動で埋め込まれていました。キャプチャの右上、URLバ ーの at= 以下が追加されています。 やりのこしうまくいかなかった場合もありました。 銭湯マップ前回ご紹介した愛用銭湯アプリ。 うまくいく場合の銭湯マップのリンクiTunesで見るから右クリックで生成した URL だと、うまく挿入されているようです。 しかし、なぜかアプリのアイコンからの右クリックコピーした URL の場合、失敗してしまいます。 [![銭湯マップ東京](http://cdn.image.st-hatena.com/image/scale/2c2b0a9dba1667b059b0076a7c1d560d1eb9b102/enlarge=0;height=200;version=1;width=200/http%3A%2F%2Fis2.mzstatic.com%2Fimage%2Fthumb%2FPurple111%2Fv4%2Fd8%2F7d%2Fe5%2Fd87de51d-6ecb-af16-e896-78a7cf453f77%2Fsource%2F100x100bb.jpg)](https://itunes.apple.com/jp/app/%E9%8A%AD%E6%B9%AF%E3%83%9E%E3%83%83%E3%83%97%E6%9D%B1%E4%BA%AC/id844039424?mt=8&uo=4&at=1000ltgN) [](https://itunes.apple.com/jp/app/%E9%8A%AD%E6%B9%AF%E3%83%9E%E3%83%83%E3%83%97%E6%9D%B1%E4%BA%AC/id844039424?mt=8&uo=4&at=1000ltgN)[![](https://cdn.blog.st-hatena.com/images/theme/itunes/itunes-badge-appstore@2x.png)](https://itunes.apple.com/jp/app/%E9%8A%AD%E6%B9%AF%E3%83%9E%E3%83%83%E3%83%97%E6%9D%B1%E4%BA%AC/id844039424?mt=8&uo=4&at=1000ltgN) アメホ愛聴させていただいている American Hot Topics のポッドキャストのリンク。 ブラウザからiTunesで見るから右クリックで生成した場合 = 成功American Hot Topics / by Kotobank iTunes アプリ内で、Subscribeを右クリック知ってコピーした URL の場合 = 失敗Subscribe アイキャッチ画像の URL の場合 = 失敗American Hot Topics / by Kotobank 失敗する場合の事象として、なぜか一瞬期待した Token が埋め込まれたリンクが開くのですが、正しく表示されず、代わりに&amp;ign-mpt=uoという文字列が入ってat=以下は削除されてしまいました。何かを Ignore していそうなタグに見えますので、おそらく JavaScript の実行がうまくいっていないのかもしれません。Developer Tools でみたところ実行自体はできていそうでしたが。 またはブラウザから iTunes.app へのリダイレクトの有無と関与しているのでしょうか・・・詳しい人教えてください・・・。あまり切り分けできておらずすみませんがしばらく様子をみてみます。 参考iTunesのURLをひとつずつ分解して解説。geoという文字列について 次回 hexo にも埋め込みたいと思います。","categories":[{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"}],"tags":[{"name":"blog","slug":"blog","permalink":"http://www.fascinatedwithtofu.com/tags/blog/"},{"name":"apple affiliate","slug":"apple-affiliate","permalink":"http://www.fascinatedwithtofu.com/tags/apple-affiliate/"}]},{"title":"【書評】サウナ・銭湯入門書籍 2016年","slug":"sauna-sento-books","date":"2017-02-16T14:39:16.000Z","updated":"2023-01-16T07:44:50.594Z","comments":true,"path":"2017/02/16/sauna-sento-books/","link":"","permalink":"http://www.fascinatedwithtofu.com/2017/02/16/sauna-sento-books/","excerpt":"はじめにもはや2月ですが、2016年の読書生活を振り返ると、思ったより仕事と直接関係のない書籍を読んでいました。その中でもサウナ・銭湯の本が3冊もありました。それらをきっかけとして筆者は2016年からサウナと銭湯にはまっており、平日はそわそわしながら退社しては、銭湯マップ東京 - AtoZ Labを引っ提げては新しいサウナ・銭湯を開拓してまいりました。","text":"はじめにもはや2月ですが、2016年の読書生活を振り返ると、思ったより仕事と直接関係のない書籍を読んでいました。その中でもサウナ・銭湯の本が3冊もありました。それらをきっかけとして筆者は2016年からサウナと銭湯にはまっており、平日はそわそわしながら退社しては、銭湯マップ東京 - AtoZ Labを引っ提げては新しいサウナ・銭湯を開拓してまいりました。 なぜサウナ・銭湯を目指すのか 頭がぱぁ〜っと開けます。合法で。体はというとパソコン仕事でかちこちになった首や外回りでパンパンになったふくらはぎをほどくことができます。 前置きはおいておいて、きっかけとなった書籍を（さっき覚えたスライドショー形式のリンクにて）ご紹介していきたいと思います。 サ道 Amazon.co.jp ウィジェット 大本命です。はじめは「蒸し暑い」「不快」「拷問」とサウナを否定していタナカカツキ氏がサウナを体験することでみるみると整っていく様子が生々しく語られている。セッション中の先人たちの会話、整う際の例のサイケデリックな見開きページ、ブッダの世界に通ずる空想の世界観、どれをとってもちょうどよい語り口です。「サ道」つまり道を広める経典たるに相応しい。 ふらっと朝湯酒 Amazon.co.jp ウィジェット 「孤独のグルメ」で知らぬ人はいなくなった泉昌之の片割れ、久住昌之氏による「朝湯」ｘ「酒」という新感覚エッセイ。主に東京の名銭湯が酒とセットでどう味わえるのかが具体的に紹介されており孤独のグルメを読まれた方であれば容易に想像できるであろう筆者の細部に渡る強いこだわりが見事に作者の主観を通して語られている。自分にとっての幸福がどの程度の規模なのかをきちんと把握されている方にしか書けない文章である。すみません。まだ紹介されている十軒のうち、1つしか足を運べていません。 ちゃっかり温泉 Amazon.co.jp ウィジェット 同じく久住氏の著書であるが、こちらは「平日の真っ昼間」ｘ「ひとり飯」という切り口。一話目のダンスのエピソードや七話目の異国人の話など、引き込まれてしまう。こんな異次元のような場所、あるかもな。と妙に納得してしまうのだ。 思えば銭湯の休憩所もそんな異次元のようなあわいに存在する場所だ。飲食もできるけど飲食店ではない。銭湯にあるけど、湯はもうない。 さいごにタナカカツキ氏がサウナ愛好家の濡れ頭巾ちゃんにインタビューした際に出た至言を引用して結びに代えたい。 もし仮に僕がサウナのない世界に行ったとして、サウナという存在自体は知っているとしたら、そのサウナの思い出だけで「整う」ことができる。サウナのことを考えるだけでもうイケますね(笑)。 もしもサウナがなくなったらどうしますか？","categories":[{"name":"Book","slug":"Book","permalink":"http://www.fascinatedwithtofu.com/categories/Book/"}],"tags":[{"name":"sauna","slug":"sauna","permalink":"http://www.fascinatedwithtofu.com/tags/sauna/"}]},{"title":"無料でできる自宅ネットワーク監視環境の構築","slug":"home-netflow-monitoring","date":"2017-02-14T15:55:12.000Z","updated":"2023-01-16T07:44:46.450Z","comments":true,"path":"2017/02/15/home-netflow-monitoring/","link":"","permalink":"http://www.fascinatedwithtofu.com/2017/02/15/home-netflow-monitoring/","excerpt":"なぜか2015年に書いたこの記事だけ検索による流入が毎日ぽつぽつあります。その補足というか顛末を書いておきたいと思います。(書いていて改めて思いますが、当時やっていた設定は本当に面倒だなと思います。前記事で紹介したalpineやphotonのような存在を活用できる現在が有難いです。)","text":"なぜか2015年に書いたこの記事だけ検索による流入が毎日ぽつぽつあります。その補足というか顛末を書いておきたいと思います。(書いていて改めて思いますが、当時やっていた設定は本当に面倒だなと思います。前記事で紹介したalpineやphotonのような存在を活用できる現在が有難いです。) 自宅ネットワークにおいて、NetFlow や Syslog を無料で手軽に可視化してみたく、Elasticsearch / Logstash / Kibana （a.k.a ELK Stack）を使って Netflow コレクタ兼 Syslog サーバを自作しました（2015年〜）。GUI や気付けたことを振り返ってご紹介します。 話さないことELK とは何か？とか、ELK のセットアップ方法などは割愛します。後述の参考リンクやこちらをご参照ください。 背景いままでは家のブロードバンドルータには高度な機能がまったくなく、ただインターネットに繋ぐだけでしたが、機会があってハイエンドなルータを入手することができたため、高度な機能を試しに使ってみました。もともときれいな GUI が用意されていますが、見える情報は NetFlow や Syslog を有効にすることで格段に増えます。 監視する必要はあるの？2016年の調査で一人あたりのスマートデバイス数は平均3台との調査もあります。家の中に目を向けると、思いつくだけでネットワークカメラ、 IRKit 、スマートロック、ラズパイ的な自作物などなど、どんな OS で、どんなネットワーク/セキュリティ特性を持つのかよくわからないけどとりあえず便利！というようなデバイスがどんどん増えていきます。 Fire TV Stick は、実体は Android ですが、そういうことを気にせず過ごしてしまうことって結構あると思います。 昨年で記憶に残っているニュースとして、中国製 Android 端末にバックドアが仕掛けられていたというものがありました。 Android端末のファームウェアに隠し機能、ユーザー情報を中国に送信 インターネットの出入口の情報が可視化できれば、変な通信を見つけやすくなるはずです。 なぜ ELK を選択したか Open Source で無償 機能追加が精力的に行われている ユーザも多くメジャーな機器のログのパーサであればたいてい Github に落ちている etc… ELKでできること+ログ収集、管理、検索システム+イベントのリアルタイムな分析およびフォレンジックな分析を実現できる+機器を横断した分析ができる 我が家の監視環境の動作概要と構成+Logstash で NetFlow や Syslog を受け取り、各種処理（パースしたり、情報を追加したり、切り出したり）をする+Elasticsearch に渡してインデックス化する+Kibana 経由でインデックスにアクセスし、グラフを作ったり、検索したりする Logstach の設定例grokやフィルタの設定を書くことでもっと作り込むことはできますが NetFlow を受け取って Elasticsearch に渡すための最小設定は以下だと思います。 input &#123; udp&#123; port =&gt; 9995 // NetFlow を受け取るポート codec =&gt; netflow&#123; definitions =&gt; &quot;/etc/logstash/conf.d/codec/netflow.yaml&quot; // NetFlow を理解するための設定（参考で後述） versions =&gt; [9] &#125; &#125; &#125; output &#123; // Elasticsearch に渡すための設定 stdout &#123; codec =&gt; rubydebug&#125; elasticsearch index =&gt; “logstash-netflow-%&#123;+YYYY.MM.dd&#125;&quot; host =&gt; &#x27;localhost&#x27; &#125; &#125; 実際に作ったダッシュボード例アウトバウンドのトラフィックのうち宛先 IPv4 アドレスを時系列でカウントした棒グラフです。ルータが、Google DNS(8.8.8.8) に対してポーリングしていることがわかります。 左上から時計回りに、+[data table]Inbound でドロップしたトラフィックの宛先ポート、プロトコル、国名+[pie chart]Deny トラフィックのプロコトルおよび宛先ポート割合+[ｍetric]Inbound で Drop した回数+[pie chart]Allow と Deny の割合+[pie chart]Deny トラフィックの国-地域名割合+[histogram]Deny トラフィックの宛先ポート別推移 その他気付けたことインバウンド（インターネットー＞家）でスキャニングされている形跡がありました。23, 80, 3389, 8080 といったwell-known port 以外に53413/udp などが観測されました。調べてみたところ同時期にこのようなレポートが JPCERT より発行されていました。JPCERT TSUBAME インターネット定点観測レポート 2015年10-12月 上記のような気付きが得られた以外にも、久しぶりに新規で勢いのある OSS を触ることができて非常に勉強になりました。 また、Syslog を含めると結構なログ量になり Java のプロセスがもっさりしてきましたので、定期的に cron + curator で削除する運用にしました。 参考Step-by-Step Setup of ELK for NetFlow AnalyticsNetflow.yam - Github","categories":[{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"}],"tags":[{"name":"elastic","slug":"elastic","permalink":"http://www.fascinatedwithtofu.com/tags/elastic/"},{"name":"elk","slug":"elk","permalink":"http://www.fascinatedwithtofu.com/tags/elk/"},{"name":"logstash","slug":"logstash","permalink":"http://www.fascinatedwithtofu.com/tags/logstash/"},{"name":"kibana","slug":"kibana","permalink":"http://www.fascinatedwithtofu.com/tags/kibana/"},{"name":"netflow","slug":"netflow","permalink":"http://www.fascinatedwithtofu.com/tags/netflow/"}]},{"title":"軽量コンテナ用 OS  alpline に dockerを入れるまで","slug":"alpine-docker-deploy","date":"2017-02-08T08:08:43.000Z","updated":"2023-01-16T07:26:27.027Z","comments":true,"path":"2017/02/08/alpine-docker-deploy/","link":"","permalink":"http://www.fascinatedwithtofu.com/2017/02/08/alpine-docker-deploy/","excerpt":"前ポストの photon に引き続きライトな環境を試しましたのでメモ。さくさくしていてよい。余談ですが、ここで初めて触った fish というシェル環境を、普段使い用 mac でも使い始めました。 はじめにこちらとこちらをそのままなぞりインストールしました。","text":"前ポストの photon に引き続きライトな環境を試しましたのでメモ。さくさくしていてよい。余談ですが、ここで初めて触った fish というシェル環境を、普段使い用 mac でも使い始めました。 はじめにこちらとこちらをそのままなぞりインストールしました。 イメージの取得本家ダウンロードサイトalpine-standard-3.5.1-x86_64.iso 環境ESXi：5.5OS：その他の Linux 2.6 64bitMemory/CPU：デフォルト 初回起動以下の通りに root ログインし、セットアップコマンドを実行。 localhost login: rootsetup-alpine その後対話に従うだけです。 注意点はこちらにある通り、Which disk(s) would you like to use? (or ‘?’ for help or ‘none’) [none] : sdaHou would you like to use it? (‘sys’, ‘data, ‘lvm’ or ‘?’ for help) [?] : sysの2点です。 ssh の設定本来よろしくないかもしれませんが root ユーザでそのまま ssh させます。/etc/ssh/sshd_configの設定からPermitRootLogin yesと変更。 つまずいた場所 - Docker がインストールできないroot@alpine ~# apk add dockerERROR: unsatisfiable constraints: docker (missing): required by: world[docker] ####解決方法こちらのフォーラムに書かれているように、edge community レポジトリを指定しないといけないようです。知っていれば簡単ですね。 apk add --no-cache --repository http://dl-cdn.alpinelinux.org/alpine/edge/main --repository http://dl-cdn.alpinelinux.org/alpine/edge/community docker docker の proxy 越えの設定/etc/init.d/docker を編集して以下2つの export 文を追記。 #!/sbin/openrc-run# Copyright 1999-2013 Gentoo Foundation# Distributed under the terms of the GNU General Public License v2export http_proxy=&quot;&lt;ipaddr&gt;:&lt;port&gt;/&quot;export https_proxy=&quot;&lt;ipaddr&gt;:&lt;port&gt;/&quot;command=&quot;$&#123;DOCKERD_BINARY:-/usr/bin/dockerd&#125;&quot;pidfile=&quot;$&#123;DOCKER_PIDFILE:-/run/$&#123;RC_SVCNAME&#125;.pid&#125;&quot;(以下略) ###確認 root@alpine ~# service docker start* Caching service dependencies ... [ ok ]* /var/log/docker.log: creating file* /var/log/docker.log: correcting mode* /var/log/docker.log: correcting ownerulimit: unrecognized option: u* Starting docker ... root@alpine ~# docker run --name ng -p 80:80 nginxUnable to find image &#x27;nginx:latest&#x27; locallylatest: Pulling from library/nginx5040bd298390: Already exists333547110842: Pull complete4df1e44d2a7a: Pull completeDigest: sha256:f2d384a6ca8ada733df555be3edc427f2e5f285ebf468aae940843de8cf74645Status: Downloaded newer image for nginx:latesthogehoge - - [08/Feb/2017:05:45:13 +0000] &quot;GET / HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36&quot; &quot;-&quot; iptables はデフォルトで stop していたので、そとから http://&lt;alpine&#39;s ipaddr&gt;/ をつつくことができます。","categories":[{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"}],"tags":[{"name":"alpine","slug":"alpine","permalink":"http://www.fascinatedwithtofu.com/tags/alpine/"},{"name":"docker","slug":"docker","permalink":"http://www.fascinatedwithtofu.com/tags/docker/"}]},{"title":"Docker を動かすための軽量 Linux、 Photon を試してみました","slug":"docker-photon-lightweight","date":"2017-02-03T17:02:46.000Z","updated":"2023-01-16T07:28:36.126Z","comments":true,"path":"2017/02/04/docker-photon-lightweight/","link":"","permalink":"http://www.fascinatedwithtofu.com/2017/02/04/docker-photon-lightweight/","excerpt":"はじめに手前の mac 環境を汚さずにいろいろできる喜びもひとしおな docker for mac ですが、会社の検証環境とかでも使いたいなと思い始めて、特化した Linux を探し始めました。なんとなく検索で引っかかった photon なる OS powered by VMware を使ってみました。","text":"はじめに手前の mac 環境を汚さずにいろいろできる喜びもひとしおな docker for mac ですが、会社の検証環境とかでも使いたいなと思い始めて、特化した Linux を探し始めました。なんとなく検索で引っかかった photon なる OS powered by VMware を使ってみました。 Vine Linux や Elementary OS でも良かったのですが、ちょっと目的がデスクトップ寄りかなと思います。 イメージの入手Photon OS by vmware今回は手前の ESXi 環境（5.5）により Photon OS, Version 1.0 — OVA with virtual hardware v10 - A pre-installed and vSphere-optimized Photon OS minimal instance configured with virtual hardware version 10.を選択しました。300MB 以下で小さい点ですでに好印象。 ＜＜＜ あとで気付きますが、Alpine とか BusyBox とか上には上がいたようです・・・検索力↓お前のDockerイメージはまだ重い💢💢💢ラズパイ等でも使われているようです。 インストールESXi 5.5.0ゲストOS：その他の 3.x Linux (64 ビットCPU：1 vCPU （あとでちゃんと見ると2 vCPU 推奨とのこと。）MEM：8192 MBとしました。VMware Photon Linux の Install ～ Docker コンテナ起動。http://techblog.clara.jp/2015/04/vmware-photon_how_to_install/ とりあえず初期設定vSphere Client でコンソールからログインします。username/password = root/changeme ですが、初回に変更を求められます。 次に、ssh するために useradd / passwd しました。 起動したときから DHCP でネットワーク周りの設定はもらえているようでしたのでそこは今回触れませんでした。余談ですが、他の軽量 Linux だとデフォルトで DHCP じゃないものがあったので、ラボでさっと試すには便利です。 とりあえず yum update…と思ったら yum がないPhoton は TDNF というパッケージ管理システムに置き換わっています。じゃあこれが何なのかというと、Tiny な DNF です。DNF とは Dandified Yum のことらしいです。Python 2 ベースでかかれ、依存関係解決がときどき失敗してしまうという Yum の抱える諸問題を解決されるために生まれた事実上の後継とのこと。詳しくはWikipediaへどうぞ。 Tiny DNF は、Github を見ると vmware さんが作られてるみたいです。Photon 用ですかね。README を読むと、repo の追加もできるようです。 Now configure repo files under /etc/yum.repos.d or your repodir following.repo format of dnf/yum. yumでは /etc/yum.conf の[main]セクションにproxy=http://(hostname):(port)/と、あと必要ならproxy_username=(username)とproxy_password=(password)を追加するとプロキシを通すことができた。DNFでは同じ内容を /etc/yum.conf ではなく /etc/dnf/dnf.conf の[main]セクションに書く。 Photonでは vi /etc/tdnf/tdnf.conf というファイルがありそこに追記しました。その後 tdnf update -y が成功しました。 yumからDNFへの移行本家サイトDocker Hub OFFICIAL の VMware Photon リポジトリが公開されました。 とりあえず Docker 起動ssh 用ユーザでログインしたあと、su して root 権限になってから docker を触り始めました。 # rpm -q dockerdocker-1.12.6-1.ph1.x86_64 systemctl start docker 再起動後も docker を最初から起動させる設定systemctl enable docker # docker versionClient:Version: 1.12.6API version: 1.24Go version: go1.6.4Git commit: 78d1802Built: Wed Jan 11 00:23:16 2017OS/Arch: linux/amd64Server:Version: 1.12.6API version: 1.24Go version: go1.6.4Git commit: 78d1802Built: Wed Jan 11 00:23:16 2017OS/Arch: linux/amd64 Proxy 設定渡しの場合、Proxy の背後にある環境だったため、docker pull image が失敗しました。Proxy環境下のDockerトラブルシューティング &lt;&lt;&lt; こちらは役に立たなかったProxy 環境下での Docker の使用方法（Docker デーモンが systemd に管理されている場合） &lt;&lt;&lt; 役に立ちました。 vi /lib/systemd/system/docker.service Environment=&#x27;http_proxy=http://&lt;ipaddr&gt;:8080&#x27; Environment=&#x27;NO_PROXY=localhost,127.0.0.0/8&#x27; systemctl daemon-reload Proxy 別の手段/lib/systemd/system/docker.serviceのなかにEnvironmentFileの記述があります。この配下に追加したい環境情報を置くこともできます。vi /etc/systemd/system/docker.service.d/http-proxy.conf [Service]Environment=&quot;HTTP_PROXY=http://&lt;ipaddr&gt;:8080&quot;Environment=&quot;NO_PROXY=localhost,127.0.0.0/8&quot; 確認systemctl show docker | grep EnviEnvironment=HTTP_PROXY=http:// NO_PROXY=localhost,127.0.0.0/8EnvironmentFile=/etc/default/docker (ignore_errors=yes) Docker が起動しない！？docker image pullしている途中で以下のエラーが出ました。unauthorized: authentication requiredhttp://qiita.com/youhei_nakagawa/items/d7bf1e83008e9ed0c68e 再起動したらなんか動いた。Bridge がおかしいとこうなるらしいです。以下記録までにログ # systemctl status docker.service -l● docker.service - Docker Daemon Loaded: loaded (/usr/lib/systemd/system/docker.service; disabled; vendor preset: enabled) Active: failed (Result: exit-code) since Thu 2017-02-02 23:36:21 UTC; 28s ago Docs: http://docs.docker.com Process: 752 ExecStart=/usr/bin/docker daemon $DOCKER_OPTS --containerd /run/containerd.sock (code=exited, status=1/FAILURE)Main PID: 752 (code=exited, status=1/FAILURE)Feb 02 23:36:21 photon-pZJ8MxSIT docker[752]: time=&quot;2017-02-02T23:36:21.875670834Z&quot; level=warning msg=&quot;Running modprobe bridge br_netfilter failed with message: , error: exit status 1&quot;Feb 02 23:36:21 photon-pZJ8MxSIT docker[752]: time=&quot;2017-02-02T23:36:21.877054039Z&quot; level=warning msg=&quot;Running modprobe nf_nat failed with message: ``, error: exit status 1&quot;Feb 02 23:36:21 photon-pZJ8MxSIT docker[752]: time=&quot;2017-02-02T23:36:21.878371360Z&quot; level=warning msg=&quot;Running modprobe xt_conntrack failed with message: ``, error: exit status 1&quot;Feb 02 23:36:21 photon-pZJ8MxSIT docker[752]: time=&quot;2017-02-02T23:36:21.880835972Z&quot; level=info msg=&quot;Firewalld running: false&quot;Feb 02 23:36:21 photon-pZJ8MxSIT docker[752]: time=&quot;2017-02-02T23:36:21.922047885Z&quot; level=info msg=&quot;Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address&quot;Feb 02 23:36:21 photon-pZJ8MxSIT docker[752]: time=&quot;2017-02-02T23:36:21.923904455Z&quot; level=fatal msg=&quot;Error starting daemon: Error initializing network controller: Error creating default \\&quot;bridge\\&quot; network: package not installed&quot;Feb 02 23:36:21 photon-pZJ8MxSIT systemd[1]: docker.service: Main process exited, code=exited, status=1/FAILUREFeb 02 23:36:21 photon-pZJ8MxSIT systemd[1]: Failed to start Docker Daemon.Feb 02 23:36:21 photon-pZJ8MxSIT systemd[1]: docker.service: Unit entered failed state.Feb 02 23:36:21 photon-pZJ8MxSIT systemd[1]: docker.service: Failed with result &#x27;exit-code&#x27;. Elasticsearch 公式 Docker を使わないのか?おっしゃる通りです。使ってみました。ElasticのDockerイメージを使って、ElasticsearchとKibanaを使う起動しました。 curl -GET http://localhost:9200&#123; &quot;name&quot; : &quot;GvpRqg9&quot;, &quot;cluster_name&quot; : &quot;elasticsearch&quot;, &quot;cluster_uuid&quot; : &quot;-1CASI3tTDeS642FvtMvrA&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;5.2.0&quot;, &quot;build_hash&quot; : &quot;24e05b9&quot;, &quot;build_date&quot; : &quot;2017-01-24T19:52:35.800Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;6.4.0&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; さいごにさくさく挙動してくれて、tdnf で従来通りいろいろ足せるので、普段使いには良さそうだなと思いました。Alpine Linux も後日試してみます。","categories":[{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://www.fascinatedwithtofu.com/tags/docker/"},{"name":"photon","slug":"photon","permalink":"http://www.fascinatedwithtofu.com/tags/photon/"},{"name":"elastic","slug":"elastic","permalink":"http://www.fascinatedwithtofu.com/tags/elastic/"}]},{"title":"Hexo と Github Pages で簡単シンプルブログを作成するときに参考にさせてもらったサイトまとめ","slug":"hexo-matome","date":"2017-02-01T16:09:29.000Z","updated":"2023-01-16T07:44:43.098Z","comments":true,"path":"2017/02/02/hexo-matome/","link":"","permalink":"http://www.fascinatedwithtofu.com/2017/02/02/hexo-matome/","excerpt":"はじめにこの記事は、Hexo のような静的サイトジェネレータ + Github Pages でサイトを作りたいと思っている人の参考となることが目的です。私自身もわからないとよく参照させてもらっているサイトなので、逆引きできるようにまとめておけたらいいなと思っていました。","text":"はじめにこの記事は、Hexo のような静的サイトジェネレータ + Github Pages でサイトを作りたいと思っている人の参考となることが目的です。私自身もわからないとよく参照させてもらっているサイトなので、逆引きできるようにまとめておけたらいいなと思っていました。 Wordpress でええやん？たしかに似ている点が沢山あります。シンプルにサイトが構築でき、そのなかでテンプレートを選べたり、Plugin を入れて機能追加して育てる点だったり。静的サイトジェネレータの場合は、レンタルサーバを借りずとも Github Pages に無料でホスティングできる点が大きな魅力だと言えます。 静的サイトジェネレータの現状こちらをみると、Jekyll, Hugo, Hexo の順番で人気がありそうです。Jekyll = Ruby, Hugo = Go, Hexo = JavaScript というように使われている言語や HTML テンプレートがそれぞれ異なりますので、いま使いたい/学習したい技術を選ぶというのもありです。Github Pagesでブログ構築ができる静的サイトジェネレーター総まとめ 環境作りから初期設定までHexo 周り公式サイト Hexoで気軽に静的ブログ作成 (1)環境導入 Github Pages 周りGit初心者でも大丈夫！完全無料でGithub PagesにWebページを公開する方法所要時間3分!? Github PagesとHEXOで爆速ブログ構築してみよう！Hexo と GitHub Pages でブログ環境を構築して公開するHexo でブログをつくるまで カスタマイズ周りコメント欄の設置Disqus 一択だと思っています。Disqusを使ってブログ（Hexo）にコメント欄を設置しました &amp; ブログにコメント欄を設置した理由その時の作業メモ：Hexo にコメント機能と自動生成目次(toc)を追加しました 独自ドメインの設定方法が知りたいかなり丁寧に解説されているサイトが多いです。GitHub Pages でWebサイトをホスティングする（独自ドメイン使用）Hexo/Github Pagesで、独自ドメインを設定するその時の作業メモ：Github Pages をお名前.com で取得した独自ドメインに変更しました 関連する投稿をレコメンド2つ選択肢がありそうです。作っちゃうのがすごいです。Hexoで関連記事や人気記事を生成するプラグインを作った関連記事を表示するHexoプラグインを作った Google Adsense 設置中国語の記事が多い印象です。HexoにGoogle Adsenseをセットアップするその時の作業メモ：Hexo に Google adsense 設置&amp;バナー編集 プラグイン全般Hexoブログで使ってるプラグインを晒してみる【Node.js】hexoのプラグインの作り方からインストールまで 別のフレームワークからの移行やったことないですが一応お見かけしたものをば。本家サイト - MigrationWordpressからHexoに移行してGitHub Pageで公開したHexoにWordPressの記事をマイグレートするサイトジェネレーターをOctopressからHexoに変更blogをpowered by Hexoにした。また見つけて追記してきます。 テンプレートに迷ったら最初は特に決めずにいろいろ hexo s して試すのが一番いいと思います。Hexoのブログデザインテーマ調べたものまとめ自作して theme を公開されている方も技術ブログのためのHexoのテーマ Ingenuous をリリースしました テンプレートから逸脱して技術的にもデザイン的にもかっこいいサイトtext perforationHexoブログで使ってるプラグインを晒してみる 最後にHexo でブログを作成してから、いろんなサイトを作成者目線で見ることが増えました。「このサイトのベースは Landscape だ」などと気付けてニヤニヤしたりできます。","categories":[{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://www.fascinatedwithtofu.com/tags/hexo/"}]},{"title":"【ライブレポート】水谷浩章 phonolite strings @ 新宿 Pit Inn","slug":"mizutani-phonolite","date":"2017-01-30T18:42:14.000Z","updated":"2023-01-16T07:37:46.617Z","comments":true,"path":"2017/01/31/mizutani-phonolite/","link":"","permalink":"http://www.fascinatedwithtofu.com/2017/01/31/mizutani-phonolite/","excerpt":"ライブ2本目 2017/01/26@Pit Inn Personnel:水谷浩章（B）梶谷裕子（Vla）平山織絵（Vc）須川崇志（Vc,B）ダレン・ムーア（Ds）田中邦和（Sax）類家心平（Tp）","text":"ライブ2本目 2017/01/26@Pit Inn Personnel:水谷浩章（B）梶谷裕子（Vla）平山織絵（Vc）須川崇志（Vc,B）ダレン・ムーア（Ds）田中邦和（Sax）類家心平（Tp） 他のバンドで水谷氏と類家氏を聴いたことがあったが、アンサンブルで一緒にやっているとは面白そうだと思いぶらりと行ってみた。3days の中日。セカンドセットからで計6曲、大きく盛り上がるわけでもないけど、愛おしいクセのある選曲だったりハーモニーだったり仕掛けだったりをたくさん楽しませてもらった。 ちなみに水谷氏や phonolite について詳しくは OTOTOY の水谷浩章インタビューを読むことをおすすめしたい。ひととなりが見えておもしろい。 セットリスト・Lonely Woman / Ornette Coleman ・Straight up and down / Eric Dolphy・Macho Woman / Ornette Coleman・やもり / 水谷浩章・Round Trip / Ornette Coleman 感想とか1曲目はオーネット・コールマンのアルバム The Shape of Jazz to Come - 1959 の冒頭曲として知っている人は知っているフリージャズのさきがけとなった曲。オーネットのバージョンではトランペットとテナーサックスという典型的なホーン構成にリズム隊がドラムとベースのみとヴォイシング役が不在。ドラムの神経質な刻みとホーンの開放的なサウンドによって奏でられるメロディは乖離して聴こえ、まことに緩い印象を与えるエキゾチックな本作であるが、水谷氏アレンジでも原作のイメージは残しており遅くて緩いイメージを持った。ただし、メロディ面でルーズな役割を類家氏と田中氏が演じる点は言うまでもなく、ハーモニー面ではなぜかドラムのダレンムーアが率先して弦楽器のボウをシンバルの縁にあてて不協和音を作り出し、そこに残りの弦楽器メンバーも加わり、和声的にも緩い世界を作り出していた。 2曲目は原作エリック・ドルフィーの Straight up and down であるが、水谷氏が ONJO 用にアレンジしたものとのこと。野放しにされたメンバー達をベースのダイナミクスひとつで指揮していた水谷氏はすこし猛獣使いのようだった。 3曲目はまたオーネットの Macho Woman。Fast swing でベースが2台となり、須川氏がリズムチェンジでテンポを変えて遊んでいたのが印象的だった。 4曲目はオリジナルのやもりという曲。またスローテンポにもどり、トランペット類家氏十八番のサブトーンによってたっぷりと歌い上げられていた。 ラストはミディアムスイングでオーネットの Round trip。ベースのキューで戻るところがわかりやすく崩れていたが、MC の内容からもこのバンドの場合はそれでオッケーだという共通認識がすでにできあがっており、彼らの自由な雰囲気を会場全体で楽しんでいたように思う。 その後アンコールでブルースを演って終了。 関連動画Lonly Woman/ Ornette ColemanStraight up and down / Eric DolphyMacho Wonam / Ornette ColemanRound trip / Ornette Coleman 関連 CD 学んだこといつも無計画に弄堂に行っていたが、香港屋台 九龍新宿店の角煮炒飯（少なめ）がライブ前フードとして最強だと気付けた。","categories":[{"name":"Music","slug":"Music","permalink":"http://www.fascinatedwithtofu.com/categories/Music/"}],"tags":[{"name":"live","slug":"live","permalink":"http://www.fascinatedwithtofu.com/tags/live/"}]},{"title":"Hexo / はてなブログに Amazon Publisher Studio を埋め込んでみたら想像以上に便利","slug":"hexo-hatena-amazon-publisher-studio","date":"2017-01-30T16:56:49.000Z","updated":"2023-01-16T07:54:46.646Z","comments":true,"path":"2017/01/31/hexo-hatena-amazon-publisher-studio/","link":"","permalink":"http://www.fascinatedwithtofu.com/2017/01/31/hexo-hatena-amazon-publisher-studio/","excerpt":"Amazon Publisher Studio とは？アマゾンが2013年ごろから作成した JavaScript 型のアマゾン・アソシエイト（アフィリエイト）リンク作成ツールです。 Amazon Publisher Studio を使うメリット今までは、本家アソシエイトサイトに行ったり、カエレバのようなツールを使ってサーバ代さえ稼げれば・・と夢見ながらアフィリエイとのリンクを作成していました。が、Publisher Studio を使えば、ブログ内の画像という画像に好きなアマゾンアソシエイトのリンクを埋め込むことができます。本来の記事の美観を損なわずにリンクを作れるというのは大きな利点ではないでしょうか？ 例えばこんな感じ","text":"Amazon Publisher Studio とは？アマゾンが2013年ごろから作成した JavaScript 型のアマゾン・アソシエイト（アフィリエイト）リンク作成ツールです。 Amazon Publisher Studio を使うメリット今までは、本家アソシエイトサイトに行ったり、カエレバのようなツールを使ってサーバ代さえ稼げれば・・と夢見ながらアフィリエイとのリンクを作成していました。が、Publisher Studio を使えば、ブログ内の画像という画像に好きなアマゾンアソシエイトのリンクを埋め込むことができます。本来の記事の美観を損なわずにリンクを作れるというのは大きな利点ではないでしょうか？ 例えばこんな感じ なんでもない Docker の GUI キャプチャにだって、参考書のリンクを埋め込められます。 設定方法アマゾン側での準備本家アソシエイトサイトに行って、Publisher Studio の管理へ進みます。新規サイトの登録から、好きなサイト／サービス名を入力してJavaScriptを生成するをクリック。 次に、下に現れた JavaScript をクリップボードにコピーします。 最後に、この JavaScript を有効化します。ツールバーを有効にするをクリック。 ちなみに詳細設定内の他のものはデフォルトから変更していません。次に、サイト内にこれを埋め込みます。 はてなブログ編ブログ管理画面から「デザイン」＞「カスタマイズ」へすすみ「フッタ」を選択 フッタを選択して先ほどの JavaScript をそのまま貼り付けて、変更を保存するで完了です。 自分のはてなブログのトップページに戻ると、amazonpublisherstudio というバーが現れているはずです。 ログインを押して、アマゾンのでログインします。 すると、画像だと判別された場所の上にマウスを当てると、リンク作成用検索バーが現れます。試しに2017年1月末時点で最新と思われる Docker 入門書 - Docker入門を埋め込んでみました。＊ちなみに本書はタイトル通り本当に初心者向けに書かれた内容となっており、まだ Docker に触ったことがない、もしくはググりながら動かせてはいるが、基礎を体系的に知っておきたい、という読者には程よい内容でした。 確認します。シークレットモードでブラウザを開き直します。こんな感じです。 Hexo ブログ編ニーズがあるかわかりませんが、少なくとも Hexo / Github Pages を使う方は、おそらく広告やアフィリエイト誘導が少ないほうが好きなんだと思います。 思いっきり今すぐ購入すると出てきますが、レイアウトのノイズは減らせるんじゃないかなと。 私の利用している landscape のテーマを例に設定方法を見てみます。実施するのは、はてなダイアリーと同じくフッタへのコード追加です。 vi themes/landscape/layout/_partial/footer.ejs &lt;footer id=&quot;footer&quot;&gt; &lt;% if (theme.sidebar === &#x27;bottom&#x27;)&#123; %&gt; &lt;%- partial(&#x27;_partial/sidebar&#x27;) %&gt; &lt;% &#125; %&gt; &lt;div class=&quot;outer&quot;&gt; &lt;div id=&quot;footer-info&quot; class=&quot;inner&quot;&gt; &amp;copy; &lt;%= date(new Date(), &#x27;YYYY&#x27;) %&gt; &lt;%= config.author || config.title %&gt;&lt;br&gt; &lt;%= __(&#x27;powered_by&#x27;) %&gt; &lt;a href=&quot;http://hexo.io/&quot; target=&quot;_blank&quot;&gt;Hexo&lt;/a&gt;&lt;!-- Start of Amazon Publisher Studio Loader --&gt; &lt;script&gt; window.amznpubstudioTag = &quot;hogehoge-22&quot;; &lt;/script&gt; &lt;!-- Do not modify the following code ! --&gt; &lt;script async=&quot;true&quot; type=&quot;text/javascript&quot; src=&quot;http://ps-jp.amazon-adsystem.com/domains/hogehoge-22_eb08f220-59e2-4a2d-b8d8-186be420abe.js&quot; charset=&quot;UTF-8&quot;&gt;&lt;/script&gt; &lt;!-- End of Amazon Publisher Studio Loader --&gt; &lt;/div&gt; &lt;/div&gt;&lt;/footer&gt; 汚く貼り付けていますが、以上です。hexo clean ＞ hexo d -g すれば同じようにトップにバーが現れ、ログインする流れになります。 その他この JavaScript はだいたい 2-400 msec ほど使って読み込まれていました。一記事全体の読み込みが 4-5sec であることを考えると誤差かと。 あと、 ヘッダに埋め込んでもいいけどフッタのほうが記事より後に読み込まれるため、読者にとって嬉しい とのブログ記事をある方が書かれていましたが、ソースが見つけられませんでした。おっしゃるとおりだと思います。 本人認証の仕組みがわかっていませんが、amazon にログインしたことのないブラウザで試してみたところ、表示されませんでした。（もちろん hatena にはログイン済み）おそらく埋め込んだサイトにアクセスしたタイミングで、アソシエイトの ID と紐付いたセッション情報をクッキーからとってくるのでしょうか。 ちなみに私の場合、はてなも hexo も画像は以前ご紹介したように Cloudup 経由で貼っていますが、問題なくリンクを埋め込められています。","categories":[{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://www.fascinatedwithtofu.com/tags/hexo/"},{"name":"amazon associate","slug":"amazon-associate","permalink":"http://www.fascinatedwithtofu.com/tags/amazon-associate/"}]},{"title":"Docker for Mac 環境で簡単に ELK Stack をビルドする2","slug":"elk-docker-deploy2","date":"2017-01-26T04:36:26.000Z","updated":"2023-01-16T07:29:06.727Z","comments":true,"path":"2017/01/26/elk-docker-deploy2/","link":"","permalink":"http://www.fascinatedwithtofu.com/2017/01/26/elk-docker-deploy2/","excerpt":"先ポスト Docker for Mac 環境で簡単に ELK Stack をビルドする1 からの続きです。バッチ処理のように静的なファイルを読み込んで可視化するところまで行います。使ったサンプルはこちらlogstash tutorial Logstash の動作確認つづき","text":"先ポスト Docker for Mac 環境で簡単に ELK Stack をビルドする1 からの続きです。バッチ処理のように静的なファイルを読み込んで可視化するところまで行います。使ったサンプルはこちらlogstash tutorial Logstash の動作確認つづき 試しに Apache のログを読み込むための、.conf ファイルを作ります。vi apache-import.conf cat conf/apache-import.conf input &#123; stdin &#123; &#125;&#125;filter &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;COMBINEDAPACHELOG&#125;&quot; &#125; &#125; date &#123; match =&gt; [ &quot;timestamp&quot; , &quot;dd/MMM/yyyy:HH:mm:ss Z&quot; ] locale =&gt; &quot;en&quot; &#125; mutate &#123; replace =&gt; &#123; &quot;type&quot; =&gt; &quot;apache_access&quot; &#125; &#125;&#125;output &#123; # stdout &#123; codec =&gt; rubydebug &#125; elasticsearch &#123; hosts =&gt; &#x27;localhost:9200&#x27; &#125;&#125; conf ファイルのテストconfig test をして、正しく動く .conf かテストします。 root@38ef067ec9de:/opt# ./logstash/bin/logstash -f conf/apache-import.conf -tSending Logstash&#x27;s logs to /opt/logstash/logs which is now configured via log4j2.propertiesConfiguration OK[2017-01-25T11:07:08,155][INFO ][logstash.runner ] Using config.test_and_exit mode. Config Validation Result: OK. Exiting Logstash ローカルの静的なファイル読み込む動作root@38ef067ec9de:/opt# ./logstash/bin/logstash -f conf/apache-import.conf &lt; testapache.log Sending Logstash&#x27;s logs to /opt/logstash/logs which is now configured via log4j2.properties[2017-01-25T11:09:49,418][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated &#123;:changes=&gt;&#123;:removed=&gt;[], :added=&gt;[&quot;http://localhost:9200&quot;]&#125;&#125;[2017-01-25T11:09:49,424][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working &#123;:url=&gt;#&lt;URI::HTTP:0x529840a6 URL:http://localhost:9200&gt;, :healthcheck_path=&gt;&quot;/&quot;&#125;[2017-01-25T11:09:49,550][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance &#123;:url=&gt;#&lt;URI::HTTP:0x529840a6 URL:http://localhost:9200&gt;&#125;[2017-01-25T11:09:49,552][INFO ][logstash.outputs.elasticsearch] Using mapping template from &#123;:path=&gt;nil&#125;[2017-01-25T11:09:49,622][INFO ][logstash.outputs.elasticsearch] Attempting to install template &#123;:manage_template=&gt;&#123;&quot;template&quot;=&gt;&quot;logstash-*&quot;, &quot;version&quot;=&gt;50001, &quot;settings&quot;=&gt;&#123;&quot;index.refresh_interval&quot;=&gt;&quot;5s&quot;&#125;, &quot;mappings&quot;=&gt;&#123;&quot;_default_&quot;=&gt;&#123;&quot;_all&quot;=&gt;&#123;&quot;enabled&quot;=&gt;true, &quot;norms&quot;=&gt;false&#125;, &quot;dynamic_templates&quot;=&gt;[&#123;&quot;message_field&quot;=&gt;&#123;&quot;path_match&quot;=&gt;&quot;message&quot;, &quot;match_mapping_type&quot;=&gt;&quot;string&quot;, &quot;mapping&quot;=&gt;&#123;&quot;type&quot;=&gt;&quot;text&quot;, &quot;norms&quot;=&gt;false&#125;&#125;&#125;, &#123;&quot;string_fields&quot;=&gt;&#123;&quot;match&quot;=&gt;&quot;*&quot;, &quot;match_mapping_type&quot;=&gt;&quot;string&quot;, &quot;mapping&quot;=&gt;&#123;&quot;type&quot;=&gt;&quot;text&quot;, &quot;norms&quot;=&gt;false, &quot;fields&quot;=&gt;&#123;&quot;keyword&quot;=&gt;&#123;&quot;type&quot;=&gt;&quot;keyword&quot;&#125;&#125;&#125;&#125;&#125;], &quot;properties&quot;=&gt;&#123;&quot;@timestamp&quot;=&gt;&#123;&quot;type&quot;=&gt;&quot;date&quot;, &quot;include_in_all&quot;=&gt;false&#125;, &quot;@version&quot;=&gt;&#123;&quot;type&quot;=&gt;&quot;keyword&quot;, &quot;include_in_all&quot;=&gt;false&#125;, &quot;geoip&quot;=&gt;&#123;&quot;dynamic&quot;=&gt;true, &quot;properties&quot;=&gt;&#123;&quot;ip&quot;=&gt;&#123;&quot;type&quot;=&gt;&quot;ip&quot;&#125;, &quot;location&quot;=&gt;&#123;&quot;type&quot;=&gt;&quot;geo_point&quot;&#125;, &quot;latitude&quot;=&gt;&#123;&quot;type&quot;=&gt;&quot;half_float&quot;&#125;, &quot;longitude&quot;=&gt;&#123;&quot;type&quot;=&gt;&quot;half_float&quot;&#125;&#125;&#125;&#125;&#125;&#125;&#125;&#125;[2017-01-25T11:09:49,632][INFO ][logstash.outputs.elasticsearch] Installing elasticsearch template to _template/logstash[2017-01-25T11:09:49,749][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output &#123;:class=&gt;&quot;LogStash::Outputs::ElasticSearch&quot;, :hosts=&gt;[&quot;localhost:9200&quot;]&#125;[2017-01-25T11:09:49,881][INFO ][logstash.pipeline ] Starting pipeline &#123;&quot;id&quot;=&gt;&quot;main&quot;, &quot;pipeline.workers&quot;=&gt;4, &quot;pipeline.batch.size&quot;=&gt;125, &quot;pipeline.batch.delay&quot;=&gt;5, &quot;pipeline.max_inflight&quot;=&gt;500&#125;[2017-01-25T11:09:49,883][INFO ][logstash.pipeline ] Pipeline main started[2017-01-25T11:09:50,379][INFO ][logstash.agent ] Successfully started Logstash API endpoint &#123;:port=&gt;9601&#125;[2017-01-25T11:09:52,898][WARN ][logstash.agent ] stopping pipeline &#123;:id=&gt;&quot;main&quot;&#125; Kibana から index の確認Kibana から見てみます。ただしくパースされていると、Create が押せるようになっています。このように、パースされたフィールドとその type が一覧で出てきます。 次に、左タブのDiscoverに移動し、右上の Timerang でLast 5 yearsを選びます。（注意）今回サンプルに用いたログが logstash tutorialから拝借したため、@timestamp が 2015年1月と古いためです。各ログ一つ一つのフィールドと中身が見えてきます。 Kibana でのお手軽な可視化これらの情報をグラフにしていきます。左タブから、Visualize＞Pie chartを選んでみます。でーんと円グラフが出てきます。 * でフィルタしているためこの time range の全てのログが対象です。 ここから、Split Slicesで、内訳を追加することができます。例えば、Aggrigation=Terms, Field=agent.keyword, Order By=Count Size=5この意味は、agent.keywordというフィールドに着目してグループ分けして、カウント数が大きい順から5つとってきて円グラフをスライスする、です。 まとめ静的なファイルの読み込みができました。次は、ダイナミックに syslog や netflow を受け取って可視化していくための設定を作ってみます。（近日中に）","categories":[{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://www.fascinatedwithtofu.com/tags/docker/"},{"name":"elastic","slug":"elastic","permalink":"http://www.fascinatedwithtofu.com/tags/elastic/"},{"name":"elk","slug":"elk","permalink":"http://www.fascinatedwithtofu.com/tags/elk/"},{"name":"logstash","slug":"logstash","permalink":"http://www.fascinatedwithtofu.com/tags/logstash/"},{"name":"kibana","slug":"kibana","permalink":"http://www.fascinatedwithtofu.com/tags/kibana/"}]},{"title":"Docker for Mac 環境で簡単に ELK Stack をビルドする1","slug":"elk-docker-deploy1","date":"2017-01-26T04:29:00.000Z","updated":"2023-01-16T07:28:33.108Z","comments":true,"path":"2017/01/26/elk-docker-deploy1/","link":"","permalink":"http://www.fascinatedwithtofu.com/2017/01/26/elk-docker-deploy1/","excerpt":"背景先ポストで書いたように、2015年頃に Elasticsearch, Logstash, Kiban あわせて ELK Stack なるものを知って、自分の検証環境の簡易 Syslog サーバとしてみたり、自宅監視用の NetfFlow コレクタにしたりしていました。 visualizing netflow version 9 on ELK 当時のログ可視化環境作り当時こんな記事はありませんでしたが、いまほど「可視化」が流行っておらず、無料のものは殆ど使い物にならない印象でした。 NetFlow コレクター(無料・フリー版)の比較検討【2016決定版】 その時の手順はというと、","text":"背景先ポストで書いたように、2015年頃に Elasticsearch, Logstash, Kiban あわせて ELK Stack なるものを知って、自分の検証環境の簡易 Syslog サーバとしてみたり、自宅監視用の NetfFlow コレクタにしたりしていました。 visualizing netflow version 9 on ELK 当時のログ可視化環境作り当時こんな記事はありませんでしたが、いまほど「可視化」が流行っておらず、無料のものは殆ど使い物にならない印象でした。 NetFlow コレクター(無料・フリー版)の比較検討【2016決定版】 その時の手順はというと、 Linux (自分はCentOS) をたてる firewalld/iptables, selinux などなどの基本設定 Java をインストール ELK をそれぞれインストールする それぞれの conf ファイルをいじいじする（ドキュメント読む＆ググる＆試行錯誤） 自動起動、自動停止、Index 整理のためのシェルスクリプトを書いたり、パフォーマンス周りのチューニング（ドキュメント読む＆ググる＆試行錯誤） そうこうしているうちに新しいバージョンの ELK が出てきてアップデート…などと、わりとお勉強色が強く、非効率的な作業が多かったです。 本当に楽になったログ可視化環境作りDocker や Vagrant といった、Infrastructure as a Code の潮流による、スタック化されたアプリケーションがある程度簡易に利用できるようになりました。vagrant and elk stack installation いまどきの手順ざっくりメモDocker の基本的な概念や用語については割愛します。まずそちらからという方は以下等をご参照ください。Dockerについて基本から最近追加された機能までまとめ Docker for Mac のインストール2016年末まで、Mac への正式サポートがなかったため、ググると混乱する可能性があります。公式サイトが英語ですが最も正確です。Get started with Docker for Mac 2017年1月でバージョンは 1.12.1 Kitematic (Docker Toolbox) のインストール楽をするために、Mac のメニューバーのクジラアイコンから、Kitematic をインストールしましょう。GUI で、好きな Docker イメージをインストールしたり、設定変更したりできるようになります。 kitematic by docker というページにリダイレクトされます。注意）現在、Kitematic は Docker Toolbox に吸収されたようです。Docker for mac と Kitematic でGUIから環境構築 Kitematic のダウンロードを指示に従って進めますと、DockerHub アカウントとの連携を促されますが、しなくとも大丈夫です。 Docker Image の検索とインストールここまでお読みいただくと既にお分かりかと思いますが、ここから例えば+NEWを押して、検索窓からelk docker-elk などと検索してみます。 たくさん出てきますね。 ELK を触ってみる例えば以下の Docker Image を入れてみます。これを選択した理由は、ダウンロード数が多く、説明分に latest から古いバージョンまで利用できる旨が説明されていたためです。sebp/elk+CREATE を押すとダウンロードとデプロイが開始されます。数分かかることもあります。 右上Settings&gt;Generalから、各種バージョン等が指定されていることがわかります。 Settings&gt;Portsでは、このコンテナとローカルホスト (Mac) が通信するための設定が記述されています。 Kibana の起動確認http://localhost:32770/ へアクセスします。本来の Kibana へは、:5601 がデフォルトですが、ここでは、PAT が設定されており、`localhost:32770’ をブラウザからたたきます。 Elasticsearch の起動確認同様に、http://localhost:32769が 従来における localhost:9200 へのアクセスで、Elasticsearch のプロセスが起動していることの確認となります。 Terminal へのアクセスEXEC をクリックすると、ターミナルアクセスができるようになります。bash が使えます。 Logstash の起動確認logstash,kibana,elasticsearchにまつわるものはoptディレクトリにあります。 cd opt/logstashしていただいて、以下のようなチュートリアルにある標準出力が出ればOKです。Timestamp + hostname + 標準出力に入力した stringとなります。 root@38ef067ec9de:/opt/logstash# ./bin/logstash -e &#x27;input &#123; stdin &#123; &#125; &#125; output &#123; stdout &#123;&#125; &#125;&#x27;hello worldSending Logstash&#x27;s logs to /opt/logstash/logs which is now configured via log4j2.propertiesThe stdin plugin is now waiting for input:[2017-01-25T10:04:59,971][INFO ][logstash.pipeline ] Starting pipeline &#123;&quot;id&quot;=&gt;&quot;main&quot;, &quot;pipeline.workers&quot;=&gt;4, &quot;pipeline.batch.size&quot;=&gt;125, &quot;pipeline.batch.delay&quot;=&gt;5, &quot;pipeline.max_inflight&quot;=&gt;500&#125;[2017-01-25T10:04:59,987][INFO ][logstash.pipeline ] Pipeline main started2017-01-25T10:05:00.012Z 38ef067ec9de hello world[2017-01-25T10:05:00,090][INFO ][logstash.agent ] Successfully started Logstash API endpoint &#123;:port=&gt;9601&#125; 長くなったので次へ続く","categories":[{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://www.fascinatedwithtofu.com/tags/docker/"},{"name":"elastic","slug":"elastic","permalink":"http://www.fascinatedwithtofu.com/tags/elastic/"},{"name":"elk","slug":"elk","permalink":"http://www.fascinatedwithtofu.com/tags/elk/"},{"name":"logstash","slug":"logstash","permalink":"http://www.fascinatedwithtofu.com/tags/logstash/"},{"name":"kibana","slug":"kibana","permalink":"http://www.fascinatedwithtofu.com/tags/kibana/"},{"name":"netflow","slug":"netflow","permalink":"http://www.fascinatedwithtofu.com/tags/netflow/"}]},{"title":"Hexo にコメント機能と自動生成目次(toc)を追加しました","slug":"hexo-disqus-toc","date":"2017-01-17T16:10:47.000Z","updated":"2023-01-16T11:37:10.936Z","comments":true,"path":"2017/01/18/hexo-disqus-toc/","link":"","permalink":"http://www.fascinatedwithtofu.com/2017/01/18/hexo-disqus-toc/","excerpt":"hexo をいじるのが目的化していますが、コメント機能と自動生成目次(toc)を追加しました。少しひっかかったところがあったのでメモしておきます・","text":"hexo をいじるのが目的化していますが、コメント機能と自動生成目次(toc)を追加しました。少しひっかかったところがあったのでメモしておきます・ コメント機能の追加Hexo の先人たち同様 Disqusを利用しました。 Disqus アカウント作成Twitter 連携でさっと済ませました。 Disqus 側設定I want to install Disqus on my site を選択 サイト名と後から必要になるshortname の作成。 先達めのやりかたと少し変更されているのか、 What platform is your site? と聞かれるので、 I don&#39;t see my platform listed, install manually with Universal Code を選択して、Finishしました。 Hexo 側設定コマンド二行です。 hexo config disqus_shortname &#123;YOUR_SHORTNAME&#125;hexo --config themes/light/_config.yml config comment_provider disqus このコマンドによって、記事のフッタ部分の ejs テンプレートに以下のようなセクションが追加されていました。＝＞訂正です。もともとのテンプレートに既に記述ありでした。 &lt;% if (!index &amp;&amp; post.comments &amp;&amp; config.disqus_shortname)&#123; %&gt;&lt;section id=&quot;comments&quot;&gt; &lt;div id=&quot;disqus_thread&quot;&gt; &lt;noscript&gt;Please enable JavaScript to view the &lt;a href=&quot;//disqus.com/?ref_noscript&quot;&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt; &lt;/div&gt;&lt;/section&gt;&lt;% &#125; %&gt; つまずいたところその後 hexo s で確認してもうまく反映されなかったのですが、hexo d -g してパブリッシュしてみると、反映されていました。 参考Disqusを使ってブログ（Hexo）にコメント欄を設置しました &amp; ブログにコメント欄を設置した理由Hexoでの記事の追加とコメント機能について 自動生成される目次（ToC: Table of Contents）の導入いいなぁと思っていたので、目次も導入しました。きっかけは、Hexoブログで使っているプラグインを晒してみる でした。その後 hexo-toc を導入してみましたが、うまくいかず、別の手段を探していた時にちょうど同様の事象にあたっている方を発見しました。Hexoに目次を自動的に追加する方法 テンプレートの編集以下を記事のテンプレートに追加します。場所は &lt;%- post.content %&gt; の上です。 vi themes/lhogehoge/layout/_partial/article.ejs &lt;% if (!index)&#123; %&gt; &lt;div id=&quot;toc&quot; class=&quot;toc-article&quot;&gt; &lt;p class=&quot;toc-title&quot;&gt;目次&lt;/p&gt; &lt;%- toc(post.content) %&gt; &lt;/div&gt;&lt;% &#125; %&gt; ただし、私の場合は、list が重複してしまったので、以下のように微調整を施しました。 &lt;% if (!index)&#123; %&gt; &lt;div id=&quot;toc&quot; class=&quot;toc-article&quot;&gt; &lt;p class=&quot;toc-title&quot;&gt;目次&lt;/p&gt;&lt;%- toc(post.content, &#123;list_number: false&#125;) %&gt; &lt;/div&gt;&lt;% &#125; %&gt; 参考在Hexo中给文章加目录(Table Of ContentsHexoブログで使っているプラグインを晒してみるHexoに目次を自動的に追加する方法","categories":[{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://www.fascinatedwithtofu.com/tags/hexo/"},{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/tags/IT/"}]},{"title":"Github Pages をお名前.com で取得した独自ドメインに変更しました","slug":"onamae","date":"2017-01-16T10:44:36.000Z","updated":"2023-01-16T07:44:47.912Z","comments":true,"path":"2017/01/16/onamae/","link":"","permalink":"http://www.fascinatedwithtofu.com/2017/01/16/onamae/","excerpt":"ゴールお名前.comとDozensというサービスを利用して簡単に username.github.io を fascinatedwithtofu.com に変更しました。やったことをざっとメモします。","text":"ゴールお名前.comとDozensというサービスを利用して簡単に username.github.io を fascinatedwithtofu.com に変更しました。やったことをざっとメモします。 独自ドメインの取得（ドメインレジストラの選定）いくつか検討しました。要件は以下です。 .com .net といったメジャーかつWhois代行が無料でできるドメイン（cf: .org は不可） 2年目以降で契約更新しても大きく金額が変わらないドメイン（cf: .site .xyz などといった格安な新gTLDドメインも2年目から2,980円/年だったりと落とし穴あり、後述） ネット上で使っている人や情報が多い（これ何気に重要） ムームードメインムームードメイン タイトルからわかるようにムームードメインは結局選びませんし、まったく話はそれますが、よく炎上されている連続起業家 家入一真氏という人がいます。 筆者はインターネットという存在のオープンさについては家入氏同様にとても気に入っていて、縁あってインターネット関連企業に勤めています。昨年読んだ家入氏の著書では、 いじめられひきこもっていた話とインターネットに助けられたエピソード 芸大受験での失敗とデザインへの興味 当時珍しかったホスティング・サービス立ち上げの話、いわゆるGMO (旧paperboy&amp;co.) の黎明期の話 などなど、いまでこそ空気のように当たり前なってしまったインターネットというインフラを、ビジネスとして、もしくは自身の心の拠り所として打ち込む物語が私の胸を打ちました。自分で0から作ってしまうのって面白そうだなぁと。 さよならインターネット - まもなく消えるその「輪郭」について (中公新書ラクレ 560)posted with ヨメレバ家入 一真 中央公論新社 2016-08-08 Kindle7net 当然、GMOのサービスを使いたいなと思いまして、まずはキャッチーなムームードメインの門戸を叩きました。が、割引の都合なのか、 ムームードメイン＝1160円 お名前ドットコム＝1040円 との結果で、お名前ドットコム（こちらもご存知の通りGMOが運営）にしました。 余談ですが、新gTLD取得のサイトが結構かわいいし使いやすいです。馬 とか乗り物 とか 色 とかわかりやすい。 格安ドメイン管理 初心者でも安心のムームードメイン お名前ドットコムお名前.com 価格面、情報の多さからも納得のお名前ドットコムちなみに2年目以降の契約料金も含めて検討しました。定価一覧で見てもいいですが、気になるドメインがあれば、空きドメインの確認の際に併せてチェックしておき、2年目でいきなり高くなる様子をご確認いただければ充分かと思います。＊続けられるかわからない場合はまずは1年間使ってみる分にはキャンペーンの新gTLDドメインもよいかもしれないですね。初年度価格：2年間の価格： ■ドメイン取るならお名前.com■ Dozens の設定お名前ドットコムの独自ドメインへアクセスすると、裏側で「実は github.io のページなんですよ」という風にそれぞれを裏で繋げてくれる仕組みが必要です。そんなインターネットの裏方作業をしてくれる名前解決を無料で実施してくれるサービスがDozensです。dozensまずはカウントを取得してログインすると、「Add a new domain」と赤字がありますので、追加していきます。次に同じく赤字の「Record」に進みます。今回の場合は、サブドメイン www として、CNAMEを選択します。下の空欄は username.github.io を入力します。 Github Page 側設定変更vi source/CNAME username.github.io http:// や https:// などは付けてはいけません。 お名前ドットコム側DNS設定お名前ドットコムの管理画面にログインし、ネームサーバの設定をDozensの指定したものに変更します。 ドメイン設定＞ネームサーバの設定＞ネームサーバの変更＞他のネームサーバを利用 確認設定変更が反映されるまで数分かかりました。 Dig コマンドを使えると、かっこいいと思います。静的サイトをgithub.ioでホスティングし、独自ドメインでアクセスする 以下も参考にさせていただきましたGitHub Pages でWebサイトをホスティングする（独自ドメイン使用）Hexo/Github Pagesで、独自ドメインを設定する","categories":[{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://www.fascinatedwithtofu.com/tags/hexo/"},{"name":"git","slug":"git","permalink":"http://www.fascinatedwithtofu.com/tags/git/"},{"name":"domain","slug":"domain","permalink":"http://www.fascinatedwithtofu.com/tags/domain/"}]},{"title":"Hexo に Google adsense 設置&バナー編集","slug":"edithexo","date":"2017-01-13T17:19:26.000Z","updated":"2023-01-16T07:28:25.103Z","comments":true,"path":"2017/01/14/edithexo/","link":"","permalink":"http://www.fascinatedwithtofu.com/2017/01/14/edithexo/","excerpt":"Hexo のレイアウトを変えたりしました。かっこいいな…! と思っていたテンプレートをうまく自分好みにカスタムする能力がなかったため、Landscape ベースで ejs ファイルを見よう見まねで編集しました。 google adsense バナー直下編本当に置きたい場所に貼るだけなんだということに衝撃を受けました。Google adsense の申請は完了している前提となります。","text":"Hexo のレイアウトを変えたりしました。かっこいいな…! と思っていたテンプレートをうまく自分好みにカスタムする能力がなかったため、Landscape ベースで ejs ファイルを見よう見まねで編集しました。 google adsense バナー直下編本当に置きたい場所に貼るだけなんだということに衝撃を受けました。Google adsense の申請は完了している前提となります。 以下の2つを参考にさせていただきました。【Hexo】Hexo环境下设置Google AdsenseHexoにGoogle Adsenseをセットアップする step1わかりやすくするためにアドセンスのコードを貼り付けるファイルを_custom_adというディレクトリ配下に置きます。＊以下すべて hogehoge = テーマ名です。mkdir theme/hogehoge/layout/_custome_adこの中に、Google adsense の管理画面で生成したコードをそのまま貼り付けます。vi themes/hogehoge/layout/_custom_ad/google_adsense.ejs &lt;script async src=&quot;//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&quot;&gt;&lt;/script&gt;(以下略) step2以下の三行を広告を載せたい場所にコピペします。 &lt;!-- ad start --&gt;&lt;%- partial(&#x27;_custom_ad/google_adsense&#x27;) %&gt;&lt;!-- ad end --&gt; トップページに置く場合、vi themes/hogehoge/layout/layout.ejs &lt;%- partial(&#x27;_partial/head&#x27;) %&gt;&lt;body&gt; &lt;div id=&quot;container&quot;&gt; &lt;div id=&quot;wrap&quot;&gt; &lt;%- partial(&#x27;_partial/header&#x27;, null, &#123;cache: !config.relative_link&#125;) %&gt; &lt;!-- ad start --&gt; &lt;%- partial(&#x27;_custom_ad/google_adsense&#x27;) %&gt; &lt;!-- ad end --&gt; &lt;div class=&quot;outer&quot;&gt; &lt;section id=&quot;main&quot;&gt;&lt;%- body %&gt;&lt;/section&gt; &lt;% if (theme.sidebar &amp;&amp; theme.sidebar !== &#x27;bottom&#x27;)&#123; %&gt; &lt;%- partial(&#x27;_partial/sidebar&#x27;, null, &#123;cache: !config.relative_link&#125;) %&gt; &lt;% &#125; %&gt; &lt;/div&gt; &lt;%- partial(&#x27;_partial/footer&#x27;, null, &#123;cache: !config.relative_link&#125;) %&gt; &lt;/div&gt; &lt;%- partial(&#x27;_partial/mobile-nav&#x27;, null, &#123;cache: !config.relative_link&#125;) %&gt; &lt;%- partial(&#x27;_partial/after-footer&#x27;) %&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; これで完了です。 google adsense 任意の場所編そうすると、広告がトップのバナー直下に出ます。さすがに Hexo のようなシンプルなブログを選んだのに広告がバナー下に出るのはおかしいだろうと思い、右カラムに表示します。 step1themes/hogehoge/layout/_widget 配下に新たに ejs を置きます。vi themes/landscape/layout/_widget/sponsor.ejs &lt;% if (site.posts.length)&#123; %&gt; &lt;div class=&quot;widget-wrap&quot;&gt; &lt;h3 class=&quot;widget-title&quot;&gt;&lt;%= __(&#x27;sponsor&#x27;) %&gt;&lt;/h3&gt; &lt;div class=&quot;widget&quot;&gt; &lt;!-- ad start --&gt; &lt;%- partial(&#x27;_custom_ad/google_adsense&#x27;) %&gt; &lt;!-- ad end --&gt; &lt;/div&gt; &lt;/div&gt;&lt;% &#125; %&gt; step2ウィジェットの項目に sponsor を追加します。vi themes/hogehoge/_config.yml (省略)sidebar: rightwidgets:- category- tag- tagcloud- archive- recent_posts- links- sponsor（省略） 完了です。 あとは、ejs ファイルにこの三行を貼ると、だいたい思った場所に広告が乗ります（テキトーですみません）。 &lt;!-- ad start --&gt;&lt;%- partial(&#x27;_custom_ad/google_adsense&#x27;) %&gt;&lt;!-- ad end --&gt; バナーの宇宙的画像を変更する美しい画像ですが、ちょっと変更してみます。Landscape-plus というサイトを参考にして、背景の色とタイトルバックの色をそれぞれ指定することにしました。https://github.com/xiangming/landscape-plus step1画像指定をコメントアウト vi themes/hogehoge/source/css/_partial/header.styl （省略）#banner // background: url(banner-url) center #000 background: #323232 // お好きな色の hex（省略）#logo（省略） background: #e8b93a // お好きな色の hex padding: 5px 10px // 間隔 border-radius: 5px // タイトルバックの四角形の角を丸く（省略） ちなみにここで banner-url となっている画像の元ネタは、下記にありますので、この画像を差し替えるとバナー画像が変えられます。 vi themes/landscape-plus/source/css/_variables.styl （省略）banner-url = &quot;images/banner.jpg&quot;（省略） 編集を反映させるときの Tips画像周りを変更すると、hexo gen -d した後の反映が遅いです。 試したこと1rm db.json参考Hexoで記事生成時に消したはずの情報で生成されるー＞しばらく待つものの反映されず・・・ 試したこと2hexo cleanHexo commandsCleans the cache file (db.json) and generated files (public).とのこと。こちらはうまく反映されました。めでたし","categories":[{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://www.fascinatedwithtofu.com/tags/hexo/"},{"name":"google adsense","slug":"google-adsense","permalink":"http://www.fascinatedwithtofu.com/tags/google-adsense/"}]},{"title":"Cloudup が便利そう","slug":"cloudup","date":"2017-01-09T15:36:47.000Z","updated":"2023-01-16T07:28:38.015Z","comments":true,"path":"2017/01/10/cloudup/","link":"","permalink":"http://www.fascinatedwithtofu.com/2017/01/10/cloudup/","excerpt":"Cloudup というサービスが便利そうブログをHexoにしてみたよ。-ポンダッドの日記Markdown にも慣れない今日このごろですが、Hexo で画像をスムーズに貼るにはどうしたらいいのか考えていて、この記事を参考にさせていただき Cloudup を利用しはじめました。キャプチャを貼りたいなと思う場面で一番直感的だと思ったからです。 ざっくりと使用感ご紹介（以下のスクショもすべて Cloudup を利用しています）","text":"Cloudup というサービスが便利そうブログをHexoにしてみたよ。-ポンダッドの日記Markdown にも慣れない今日このごろですが、Hexo で画像をスムーズに貼るにはどうしたらいいのか考えていて、この記事を参考にさせていただき Cloudup を利用しはじめました。キャプチャを貼りたいなと思う場面で一番直感的だと思ったからです。 ざっくりと使用感ご紹介（以下のスクショもすべて Cloudup を利用しています） サインアップcloudup.com へいってサインアップします。設定することは特にないです。 ログイン後こんな画面が最初に待ち構えています。 アップロードここにアップしたい画像をドラッグアンドドロップするか、クリップボードにコピーしてある場合はペーストをすると即座にアップロードが始まります。 直リンク取得右上の MORE &gt; DIRECT URL をクリックすると、画像への .png リンクが得られますし、そのままの URL バーのアドレスもそのままシェアできます。Markdown ですと下のような記述で完了です。 デスクトップアプリの利用ブラウザだけでなくデスクトップアプリを入れると、トップのメニューバーに Cloudup が常駐して、Paste your clipboard を選択すると即座にアップロードされます 容量の制限過去の使い方記事を見ると200GBとのことですが、ログイン画面から見ると1000ファイルまでのようです。ただし削除した分に関してはまたカウントが戻るようで、ちょっとした共有用途であればしばらく制限は気にせず使えるのではないでしょうか。 デメリットGithub 上で完結させたい場合は、違う方法がいいという意見もあるようです。Cloudup 類似サービス imgur を紹介しているページ その他Wordpress.com の親会社というものがあることすら知りませんでしたが、Automattic 社が Cloudup を買収していたようです。Automatticがファイル共有サービスCloudupを買収, Wordpressに共同編集機能が加わるよくわからないけどすごく楽しそうな Cloudup 公式 Youtubeサービスが継続するといいですね。","categories":[{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://www.fascinatedwithtofu.com/tags/hexo/"}]},{"title":"Google 先生に聞いても意外とわからなかったウェブスクレイピング実践編2","slug":"scraping3","date":"2017-01-09T06:41:05.000Z","updated":"2023-01-16T07:50:20.098Z","comments":true,"path":"2017/01/09/scraping3/","link":"","permalink":"http://www.fascinatedwithtofu.com/2017/01/09/scraping3/","excerpt":"先ポストの続きです。今回はもう少し複雑なことを実施してみます。Nokogiri だけでなく、Ruby 用スクレイピングフレームワーク Anemone を使います。","text":"先ポストの続きです。今回はもう少し複雑なことを実施してみます。Nokogiri だけでなく、Ruby 用スクレイピングフレームワーク Anemone を使います。 やりたいこと4：自分が観た映画のリストの取得正規表現書き途中で自信がないですが・・・ sample4.rb# -- coding: utf-8require &#x27;nokogiri&#x27;require &#x27;anemone&#x27;opts = &#123;depth_limit: 1&#125;URL = &quot;https://filmarks.com/users/&lt;Username&gt;&quot; # Username を入れてくださいAnemone.crawl(URL, opts) do |anemone|anemone.focus_crawl do |page|page.links.keep_if &#123; |link|link.to_s.match(/&lt;Username&gt;?page=d+/) # ここ、自信ないです&#125;endanemone.on_every_page do |page|doc = Nokogiri::HTML.parse(page.body)titles = doc.xpath(&quot;//html/body/div[3]/div[3]/div[1]/div/h3/a&quot;)titles.each do |title|p title.textendendend ruby sample4.rb結果です。 &quot;ファンタスティック・ビーストと魔法使いの旅&quot; &quot;ローグ・ワン／スター・ウォーズ・ストーリー&quot; &quot;ブルーに生まれついて&quot; &quot;この世界の片隅に&quot; &quot;湯を沸かすほどの熱い愛&quot; （長いため以下略) ```###やりたいこと5：スコアも一緒に取得したいタイトルと一緒にスコアを一緒に取得してみたいと思います。``` ruby: sample5.rb # -- coding: utf-8require &#x27;nokogiri&#x27;require &#x27;anemone&#x27;opts = &#123;depth_limit: 1&#125;URL = &quot;https://filmarks.com/users/hogehoge&quot; # hogehoge に Username を入れてくださいAnemone.crawl(URL, opts) do |anemone|anemone.focus_crawl do |page|page.links.keep_if &#123; |link|link.to_s.match(/hogehoge?page=d+/) # ここ、自信ないです&#125;endanemone.on_every_page do |page|doc = Nokogiri::HTML.parse(page.body)# 本当は title と score を分けて記述したかったが、うまくとりだせなかったため、&quot;｜&quot;をつかって一度の繰り返しのなかで該当する要素を OR で抽出しています。 titlescores = doc.xpath(&#x27;//html/body/div[3]/div[3]/div[1]/div/h3/a/text()|//html/body/div[3]/div[3]/div[1]/div/div/div[3]/a/span/text()&#x27;) titlescores.each do |titlescore| p titlescore.textendendend```実行します。`ruby sample5.rb`結果です。 “ファンタスティック・ビーストと魔法使いの旅”“3.5”“ローグ・ワン／スター・ウォーズ・ストーリー”“4.0”“ブルーに生まれついて”“4.2”“湯を沸かすほどの熱い愛”“5.0”(以下省略) ```こんな形で好きな要素を複数取ってくることもできました。が、だいたいusername?page=5までで止まっているようです。 やりたいこと6：Clips で試してみる正規表現の部分がおかしいのだと思いますが、うまくいっていないため、今度は観た映画ではなく、観たい映画としてクリップしているタイトルとその平均スコアを取ってきたいと思います。場所はhttp://…/users/hogehoge/clips?=&lt;数字&gt;です。 sample6.rb# Clips は配下ディレクトリにあるため、観た映画より試しやすいです。require &#x27;nokogiri&#x27;require &#x27;anemone&#x27;opts = &#123; depth_limit: 2&#125;URL = &quot;https://filmarks.com/users/rrr&quot; # hogehoge に Username を入れてくださいAnemone.crawl(URL, opts) do |anemone| anemone.focus_crawl do |page| page.links.keep_if &#123; |link| link.to_s.match(/clips/) &#125; end anemone.on_every_page do |page|doc = Nokogiri::HTML.parse(page.body) titlescores = doc.xpath(&#x27;//html/body/div[3]/div[3]/div[1]/div/h3/a/text()|//html/body/div[3]/div[3]/div[1]/div/div/div[3]/a/span/text()&#x27;) titlescores.each do |titlescore| p titlescore.text end endend 実行しますruby example6.rb結果抜粋です。 &quot;ディア・ハンター&quot;&quot;4.0&quot;&quot;ジキル博士とハイド氏&quot;&quot;3.3&quot;&quot;俺たちは天使じゃない&quot;&quot;3.5&quot;&quot;俺たちは天使じゃない&quot;&quot;3.6&quot;&quot;ライトスタッフ&quot;&quot;3.8&quot; こちらはきちんと全部取り出せていました。 参照Anemoneによるクローラー入門Anemone - Information and Examplesパイプ以外にも便利な表現が沢山ありますね。XPath Cheat Sheet","categories":[{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"}],"tags":[{"name":"scraping","slug":"scraping","permalink":"http://www.fascinatedwithtofu.com/tags/scraping/"},{"name":"ruby","slug":"ruby","permalink":"http://www.fascinatedwithtofu.com/tags/ruby/"}]},{"title":"Google 先生に聞いても意外とわからなかったウェブスクレイピング実践編1","slug":"scraping2","date":"2017-01-09T06:24:07.000Z","updated":"2023-01-16T07:49:51.581Z","comments":true,"path":"2017/01/09/scraping2/","link":"","permalink":"http://www.fascinatedwithtofu.com/2017/01/09/scraping2/","excerpt":"先ポスト↓からの続きです。前置きはいいよ！ということで実際にスクレイピングしていきます。しかしながら HTML の構造は、作り手とコンテンツ次第で千差万別です。（それ故スクレイピングには一通りの正解のようなものがないのだと思います）よってここからは、やりたいことごとにサンプルコードを実行して結果を見てみたいと思います。 環境初っ端からはしょって申し訳ありませんが、スクレイピングの手段として、Ruby, Nokogiri を使います。（Scrapy はコピペしかできない私にはまだ早かったです。）・ruby 2.3.1p やりたいこと1：基本サンプルの実行","text":"先ポスト↓からの続きです。前置きはいいよ！ということで実際にスクレイピングしていきます。しかしながら HTML の構造は、作り手とコンテンツ次第で千差万別です。（それ故スクレイピングには一通りの正解のようなものがないのだと思います）よってここからは、やりたいことごとにサンプルコードを実行して結果を見てみたいと思います。 環境初っ端からはしょって申し訳ありませんが、スクレイピングの手段として、Ruby, Nokogiri を使います。（Scrapy はコピペしかできない私にはまだ早かったです。）・ruby 2.3.1p やりたいこと1：基本サンプルの実行 Qiita で拾ってきたサンプル（URL を変更しました）。Nokogiriで文字化けを防ぐ - Qiita sample1.rb# -- coding: utf-8require &quot;open-uri&quot;require &quot;rubygems&quot;require &quot;nokogiri&quot;url = &quot;https://filmarks.com/people/63083&quot;charset = nilhtml = open(url) do |f| charset = f.charset f.readenddoc = Nokogiri::HTML.parse(html, nil, charset)p doc.title```実行します。`ruby samble1.rb`結果です。`&quot;宮沢りえの出演・関連映画作品・プロフィール | Filmarks&quot;`何をしたかというと、対象のウェブページのソースにおける、title 部分を取得してきたことになります。ブラウザで右クリックして&quot;View Page Source&quot;となる部分です（画像は Chrome の例）![f:id:rrringress:20170108005048p:plain](https://cdn-ak.f.st-hatena.com/images/fotolife/r/rrringress/20170108/20170108005048.png &quot;f:id:rrringress:20170108005048p:plain&quot;)![f:id:rrringress:20170108013438p:plain](https://cdn-ak.f.st-hatena.com/images/fotolife/r/rrringress/20170108/20170108013438.png &quot;f:id:rrringress:20170108013438p:plain&quot;)###やりたいこと2：宮沢りえの出演映画を取得次に、ちょっと応用です。スクレイピングでは何かの一覧を取得する利用例が多いです。ここでは宮沢りえさんの出演映画をリストとして取得してみたいと思います。今度はソースコードでもいいのですが、&quot;デベロッパーツール&quot;を使って、Xpath （DOM 構造における住所）を取得してみたいと思います。試しに「湯を沸かすほどの熱い愛」はどこか確認してみます。Chrome で、View &gt; Developer &gt; Developer Tools を表示します。「▶」をたどって該当する場所を上記画像のように探し、右クリックで&quot;Copy XPath&quot;すると、クリップボードに /html/body/div[3]/div[2]/div/div[1]/h3 と保存されます。![f:id:rrringress:20170108010639p:plain](https://cdn-ak.f.st-hatena.com/images/fotolife/r/rrringress/20170108/20170108010639.png &quot;f:id:rrringress:20170108010639p:plain&quot;)余談ですが、CSS を使って DOM の住所を指定したい場合は、&quot;Copy Selector&quot; を選びます。先ほどの sample1.rb の最終行の puts するものを、xpath によって変更します。```ruby: sample2.rb# -- coding: utf-8require &quot;open-uri&quot;require &quot;rubygems&quot;require &quot;nokogiri&quot;url = &quot;https://filmarks.com/people/63083&quot;charset = nilhtml = open(url) do |f| charset = f.charset f.readenddoc = Nokogiri::HTML.parse(html, nil, charset)# doc.xpath(&quot;&lt;xpathで指定したい場所&gt;&quot;# doc.css(&quot;&lt;cssで指定したい場所&gt;&quot;)p doc.xpath(&quot;//html/body/div[3]/div[2]/div/div[1]/h3&quot;).text```実行します。`ruby samble2.rb`結果です。`&quot;湯を沸かすほどの熱い愛&quot;`###やりたいこと3：宮沢りえの出演映画を一覧で取得最後にもうちょっと応用です。これだけでは1タイトルしか取得できていませんので、次に繰り返し構文を用いて、同様の属性を持つものを順番に取得していきます。__同様の属性とはこの場合何なのでしょうか？__ もう一度デベロッパーツールを参照します。右隣りにある映画&quot;TOO YOUNG TO DIE！ 若くして死ぬ&quot;のタイトルを表示する XPATH は /html/body/div[3]/div[2]/div/div[2]/h3です。先ほどと比較すると、h3 タグの手前の div がタイトルごとに変わっていくと推測されます。（このあたりの具体的な方法から、あまりぐぐりきることができず、筆者は時間を浪費しました・・・orz）似たようなツリーが多すぎて、もう少し丁寧に指定してあげたいときは、class を指定したりしますが、その際は以下を参考にしました。[XPath Cheat Sheet](http://blog.bangboo.com/sub/xpath.html)[スクレイピングのためのNokogiri利用メモ - それはそれ。これはこれ。](http://d.hatena.ne.jp/otn/20090509/p1)``` ruby: sample3.rb# -- coding: utf-8require &quot;open-uri&quot;require &quot;rubygems&quot;require &quot;nokogiri&quot;url = &quot;https://filmarks.com/people/63083&quot;charset = nilhtml = open(url) do |f| charset = f.charset f.readenddoc = Nokogiri::HTML.parse(html, nil, charset)titles = doc.xpath(&quot;//html/body/div[3]/div[2]/div/div/h3&quot;)titles.each do |title|p title.textend```実行します。`ruby samble3.rb`結果です。未鑑賞タイトルが多いですが、ひとまず言えることとして直近の2作品は最高でした。（鑑賞してお薦めできるものはリンク付けています。） “湯を沸かすほどの熱い愛”“TOO YOUNG TO DIE！ 若くして死ぬ”“トイレのピエタ”“紙の月”“魔女の宅急便”“映画 謎解きはディナーのあとで”“The Moment -写真家の欲望-““ブラックボード 〜時代と戦った教師たち〜／第一夜 軍国主義[未来]”“夢のまにまに”“ゼラチンシルバーLOVE”“オリヲン座からの招待状”“花よりもなほ”“晴れた家”“阿修羅城の瞳”“父と暮せば”“トニー滝谷”“北の国から 2002遺言”“たそがれ清兵衛”“ノートルダムの鐘 II”“うつつ”“華の愛 遊園驚夢”“釣りバカ日誌12 史上最大の有給休暇”“運転手の恋”“北の国から’98時代”“北の国から’95秘密”“天守物語”“蛍の光”“四十七人の刺客”“欽ちゃんのシネマジャック3 ほのぼの編”“エロティックな関係”“豪姫”“どっちにするの。”“ぼくらの七日間戦争”```では、一つのページから複数の要素を取ってきたり、複数ページにまたがるスクレイピングをしたい場合についてはどうでしょうか？長くなったため、次のポストで試してみたいと思います。 まとめ簡易なスクレイピングのチュートリアルができました。Filmarks さん、勝手に利用して申し訳ありませんでした。いつも愛用させていただいております。filmarks.comその他参照 Nokogiri 本家サイト映画.com でスクレイピングを実施している例 RubyのNokogiriを使ってサイトをスクレイピングする - Think Big Act Local 書籍類 ー自動化や運用までの道のりについても触れられており、満足度の高い内容です。環境作りから丁寧に解説されています。","categories":[{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"}],"tags":[{"name":"scraping","slug":"scraping","permalink":"http://www.fascinatedwithtofu.com/tags/scraping/"},{"name":"ruby","slug":"ruby","permalink":"http://www.fascinatedwithtofu.com/tags/ruby/"}]},{"title":"Google 先生に聞いても意外とわからなかったウェブスクレイピング基礎編","slug":"scraping1","date":"2017-01-08T13:21:42.000Z","updated":"2023-01-16T07:44:31.826Z","comments":true,"path":"2017/01/08/scraping1/","link":"","permalink":"http://www.fascinatedwithtofu.com/2017/01/08/scraping1/","excerpt":"はじめに去年からチラチラ気になっていたウェブスクレイピングなるものについて、年末年始にまとまって調べることができました。結論、Nokogiri, Scrapy, Goutte, などなど方法に特化した情報が多いため分からないことだらけでしたが、なんとかコーディング能力のない（プログラムを0から書いた経験無い）自分が勘所をつかむに至った情報だけを整理します。","text":"はじめに去年からチラチラ気になっていたウェブスクレイピングなるものについて、年末年始にまとまって調べることができました。結論、Nokogiri, Scrapy, Goutte, などなど方法に特化した情報が多いため分からないことだらけでしたが、なんとかコーディング能力のない（プログラムを0から書いた経験無い）自分が勘所をつかむに至った情報だけを整理します。 スクレイピングとは何か？ざっくりいうと、ウェブサイトにある情報のうち、欲しい部分だけを抽出する技術のことです。 ウェブスクレイピング（英: Web scraping）とは、ウェブサイトから情報を抽出するコンピュータソフトウェア技術のこと。ウェブ・クローラー[1]あるいはウェブ・スパイダー[2]とも呼ばれる。 通常このようなソフトウェアプログラムは低レベルのHTTPを実装することで、もしくはウェブブラウザを埋め込むことによって、WWWのコンテンツを取得する。ウェブスクレイピング - Wikipedia クローリング？ API ?クローリングという単語が併せて紹介されていることが多いが、クローリングとは人が実際にウェブブラウザでウェブサイトを閲覧する行為を、プログラムを使って擬似的に再現する行為であり、スクレイピングをする上で必要となる手段の一つという位置付けです。近年ではログイン行為のように人がブラウザで何か反応しないと目的のページに到達できない動的ページが増えているため、クローリングの重要性が増しています。また、対比される技術として API (Application Programming Interface) があります。情報を外から呼び出すための仕組みがそもそも用意されていれば、ウェブスクレイピングのようなある種力技（？）はそもそも不要です。 一応マナーがありますので、知らなかったで済まないこんな世の中を生き抜くために参照してください。 ウェブスクレイピングのメリット個人用途+いろいろなEコマースサイトから欲しい商品と価格情報を定期的に抽出し、比較検討の材料とする（価格コムがあればいらないですが・・・）+広告が多くて辟易するサイトをスッキリ表示させる（Cleary というサービスが昔ありましたね）+ローソンのおでんの価格一覧を取得する（楽しそうですね！）Rubyでスクレイピングに挑戦してみた - コンパイラかく語りき ビジネス用途+いろいろな銀行の口座情報を一つのアプリから表示させるサービスを開発する（思い当たるサービスがいくつかありますが、以下の記事がどストライクです。FinTech市場拡大に向けて注視していくべきポイント――スクリーンスクレイピングの現状と今後の銀行によるAPI公開をめぐる課題 | 市場調査の矢野経済 ICTユニット）+ソーシャルメディア分析+各種まとめサイトの自動運用 ウェブスクレイピングの前提となる知識ウェブスクレイピングは HTLM （ふだんわれわれがブラウザで見ている情報の記述ルール）を利用します。そのなかでも理解すべき情報は、DOM です。具体的には、CSS や XPATH です。 DOM とは？DOM（Document Object Model）とは、文書の中の情報（見出し１、本文、URL リンク、etc.）をツリー構造のように持つことができるよね？という概念です。みなさんも文章を書くとき、目次を考えたり構成を考えたりしますよね？ DOMとは - JavaScript超初心者によるJavaScript入門講座 CSSCSS（Cascading Style Sheets）とは、ウェブサイトの見た目をクールに整理するためのものです。DOM という概念のもと、文章の中身ではなく、スタイルを指定するものです。 XPathDOM という概念を使って、実際に欲しい情報の場所を指定するための言語です。「Body 配下の最初の Div タグの中の文章が欲しい」などの記述ができます。 基本的なスクレイピングの流れ+欲しい情報がどの DOM （住所）にあるか確認する+情報を取得する+（必要なら）取得した情報を加工する+なにがしかに出力する （text, json, etc.） 長くなってきたので講釈はここまでとのことで、次の記事に私が試行錯誤した実践編を書きたいと思います。","categories":[{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"}],"tags":[{"name":"scraping","slug":"scraping","permalink":"http://www.fascinatedwithtofu.com/tags/scraping/"},{"name":"ruby","slug":"ruby","permalink":"http://www.fascinatedwithtofu.com/tags/ruby/"}]},{"title":"Visualizing Netflow version 9 on ELK","slug":"netflow","date":"2015-08-24T10:04:19.000Z","updated":"2023-01-16T07:40:00.052Z","comments":true,"path":"2015/08/24/netflow/","link":"","permalink":"http://www.fascinatedwithtofu.com/2015/08/24/netflow/","excerpt":"prerequirement Elasticsearch / Logstash / Kibana are enabledsee alsoAmazon AWS Elastic Stackvagrant and elk stack installation firewalld is permitting netflow export port","text":"prerequirement Elasticsearch / Logstash / Kibana are enabledsee alsoAmazon AWS Elastic Stackvagrant and elk stack installation firewalld is permitting netflow export port router settingsho verCisco IOS Software, C800 Software (C800-UNIVERSALK9-M), Version 15.3(3)M2, RELEASE SOFTWARE (fc1)Technical Support: http://www.cisco.com/techsupportCopyright (c) 1986-2014 by Cisco Systems, Inc.Compiled Thu 30-Jan-14 02:12 by prod_rel_team flow record ELK-r match ipv4 tos match ipv4 protocol match ipv4 source address match ipv4 destination address match transport source-port match transport destination-port match interface input collect routing forwarding-status collect routing next-hop address ipv4 collect ipv4 dscp collect ipv4 ttl minimum collect ipv4 ttl maximum collect transport tcp flags collect interface output collect counter bytes collect counter packets collect timestamp sys-uptime first collect timestamp sys-uptime last collect timestamp absolute first collect timestamp absolute lastflow exporter ELK-e destination *collectorIpAddr* transport udp 9996 template data timeout 15 option interface-table timeout 15 option exporter-stats timeout 15 option application-table timeout 15 option application-attributes timeout 15flow monitor ELK-m exporter ELK-e cache timeout active 60 record EFK-rInterface *hoge* ip flow monitor EFK-m input ip flow monitor EFK-m output start logstash service/opt/logstash/bin/logstash -f /etc/logstash/conf.d/1-netflow.conf &amp; If collector correctly begin to receive netflow, console looks like: &#123; &quot;@timestamp&quot; =&gt; &quot;2015-08-24T10:04:08.000Z&quot;, &quot;netflow&quot; =&gt; &#123; &quot;version&quot; =&gt; 9, &quot;flow_seq_num&quot; =&gt; 23504, &quot;flowset_id&quot; =&gt; 260, &quot;ipv4_src_addr&quot; =&gt; &quot;0.0.0.0&quot;, &quot;ipv4_dst_addr&quot; =&gt; &quot;255.255.255.255&quot;, &quot;input_snmp&quot; =&gt; 16, &quot;l4_src_port&quot; =&gt; 49460, &quot;l4_dst_port&quot; =&gt; 10067, &quot;src_tos&quot; =&gt; 0, &quot;protocol&quot; =&gt; 17, &quot;tcp_flags&quot; =&gt; 0, &quot;min_ttl&quot; =&gt; 254, &quot;max_ttl&quot; =&gt; 254, &quot;ipv4_next_hop&quot; =&gt; &quot;0.0.0.0&quot;, &quot;in_bytes&quot; =&gt; 134, &quot;in_pkts&quot; =&gt; 1, &quot;first_switched&quot; =&gt; &quot;2015-08-24T10:03:53.999Z&quot;, &quot;last_switched&quot; =&gt; &quot;2015-08-24T10:03:53.999Z&quot;, &quot;output_snmp&quot; =&gt; 0 &#125;, &quot;@version&quot; =&gt; &quot;1&quot;, &quot;host&quot; =&gt; &quot;10.71.146.222&quot;&#125; If you see error messages like: No matching template for flow id 260 &#123;:level=&gt;:warn&#125;Unsupported field &#123;:type=&gt;152, :length=&gt;8, :level=&gt;:warn&#125; You could define length or skip them. vi /etc/logstash/codec/v9.yaml 260:- :skip original netflow codec - Github","categories":[{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"}],"tags":[{"name":"elastic","slug":"elastic","permalink":"http://www.fascinatedwithtofu.com/tags/elastic/"},{"name":"elk","slug":"elk","permalink":"http://www.fascinatedwithtofu.com/tags/elk/"},{"name":"netflow","slug":"netflow","permalink":"http://www.fascinatedwithtofu.com/tags/netflow/"}]},{"title":"chef, knife-solo installation","slug":"chef","date":"2015-08-05T07:31:17.000Z","updated":"2023-01-16T07:28:40.084Z","comments":true,"path":"2015/08/05/chef/","link":"","permalink":"http://www.fascinatedwithtofu.com/2015/08/05/chef/","excerpt":"First step to install chef. env memoCentos 7 ruby -vruby 2.0.0p598 (2014-11-13) [x86_64-linux]","text":"First step to install chef. env memoCentos 7 ruby -vruby 2.0.0p598 (2014-11-13) [x86_64-linux] refhttp://learn.chef.io/learn-the-basics/rhel/http://tsuchikazu.net/chef_solo_start/http://qiita.com/TsuyoshiUshio@github/items/89030baca68b05a9783d chef installationIf you use proxy -p option is required gem -i chef –no-ri –no-rdoc -p http://yourproxy:8080 gem list | grep chefchef (12.4.1)chef-config (12.4.1)chef-zero (4.2.3) knife configurationknife configureWARNING: No knife configuration file foundWhere should I put the config file? [/root/.chef/knife.rb] Please enter the chef server URL: [https://localhost:443] Please enter an existing username or clientname for the API: [root] Please enter the validation clientname: [chef-validator] Please enter the location of the validation key: [/etc/chef-server/chef-validator.pem] Please enter the path to a chef repository (or leave blank): *****You must place your client key in: /root/.chef/root.pemBefore running commands with Knife!*****You must place your validation key in: /etc/chef-server/chef-validator.pemBefore generating instance data with Knife!*****Configuration file written to /root/.chef/knife.rb All setting are left as default. knife-solo installationFetching: knife-solo-0.4.2.gem (100%)Thanks for installing knife-solo!If you run into any issues please let us know at: https://github.com/matschaffer/knife-solo/issuesIf you are upgrading knife-solo please uninstall any old versions byrunning `gem clean knife-solo` to avoid any errors.See http://bit.ly/CHEF-3255 for more information on the knife bugthat causes this.Successfully installed knife-solo-0.4.21 gem installed creating repositoryknife solo init chef-repoCreating kitchen...Creating knife.rb in kitchen...Creating cupboards...ls chef-repo/cookbooks data_bags environments nodes roles site-cookbooks chef login settingvi /root/.chef/root.pemchmod 600 /root/.chef/root.pem downloading cookbookgem i berkshelf --no-ri --no-rdocvi Berksfilesite :opscodecookbook &#x27;yum&#x27;cookbook &#x27;nginx&#x27; berks vendor cookbooks To be continued…","categories":[{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"}],"tags":[{"name":"chef","slug":"chef","permalink":"http://www.fascinatedwithtofu.com/tags/chef/"}]},{"title":"Vagrant and ELK stack installation","slug":"vagrant","date":"2015-07-21T05:53:32.000Z","updated":"2023-01-16T07:46:58.821Z","comments":true,"path":"2015/07/21/vagrant/","link":"","permalink":"http://www.fascinatedwithtofu.com/2015/07/21/vagrant/","excerpt":"vagrant, VirtualBox を mac にインストールして、elasticsearch, logstash, kibana a.k.a elk stack が入った box を起動します","text":"vagrant, VirtualBox を mac にインストールして、elasticsearch, logstash, kibana a.k.a elk stack が入った box を起動します vagrant installvagrant downloaddmg を落としてインストール % vagrant --versionVagrant 1.7.4 VirtualBox installVirtualBox downloaddmg を落としてインストールついでに extension pack も入れた elk stack installgit clone https://github.com/comperiosearch/vagrant-elk-box.gitCloning into &#x27;vagrant-elk-box&#x27;...remote: Counting objects: 327, done.remote: Total 327 (delta 0), reused 0 (delta 0), pack-reused 327Receiving objects: 100% (327/327), 51.51 KiB | 0 bytes/s, done.Resolving deltas: 100% (153/153), done.Checking connectivity... done. cd vagrant-elk-box vagrant up Provisioningvagrant provision&lt;snip&gt;==&gt; default: Notice: /Stage[main]/Main/Elasticsearch::Instance[es-01]/Elasticsearch::Service[es-01]/Elasticsearch::Service::Init[es-01]/Service[elasticsearch-instance-es-01]/ensure: ensure changed &#x27;stopped&#x27; to &#x27;running&#x27;==&gt; default: Notice: /Stage[main]/Main/Exec[start kibana]/returns: executed successfully==&gt; default: Notice: Finished catalog run in 36926.37 seconds けっこう待ちました vagrant sshしてss -atunでサービスを確認する vagrant@localhost:~$ ss -atun | grep 9200 tcp ESTAB 0 0 127.0.0.1:41495 127.0.0.1:9200 tcp ESTAB 0 0 127.0.0.1:41496 127.0.0.1:9200 tcp LISTEN 0 50 :::9200 :::* tcp ESTAB 0 0 ::ffff:127.0.0.1:9200 ::ffff:127.0.0.1:41495 tcp ESTAB 0 0 ::ffff:127.0.0.1:9200 ::ffff:127.0.0.1:41496 vagrant@localhost:~$ ss -atun | grep 5601tcp LISTEN 0 128 *:5601 *:* vagrant@localhost:~$ curl -XGET localhost:9200&#123; &quot;status&quot; : 200, &quot;name&quot; : &quot;localhost-es-01&quot;, &quot;cluster_name&quot; : &quot;vagrant_elasticsearch&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;1.6.1&quot;, &quot;build_hash&quot; : &quot;e72f2849e1c52f2a7b87196b36e687f851a30a6a&quot;, &quot;build_timestamp&quot; : &quot;2015-07-16T14:06:55Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;4.10.4&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125;vagrant@localhost:~$ 次はここで Netflow などを読み込むための設定を追加したいと思います可能なら puppet の段階で実施するのも良いのかもしれないですね","categories":[{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"}],"tags":[{"name":"elk","slug":"elk","permalink":"http://www.fascinatedwithtofu.com/tags/elk/"},{"name":"vagrant","slug":"vagrant","permalink":"http://www.fascinatedwithtofu.com/tags/vagrant/"}]},{"title":"Hexo セットアップメモ","slug":"hexo","date":"2015-07-18T16:01:49.000Z","updated":"2023-01-16T07:34:57.527Z","comments":true,"path":"2015/07/19/hexo/","link":"","permalink":"http://www.fascinatedwithtofu.com/2015/07/19/hexo/","excerpt":"はじめに ELK などを触っていてメモする場所が欲しくなり、以前ぜんぜん詳しくもないのになぜか触ったことがある hexo を思い出すも Node.js をはじめから設定する必要があり、手始めに初期設定をメモします。","text":"はじめに ELK などを触っていてメモする場所が欲しくなり、以前ぜんぜん詳しくもないのになぜか触ったことがある hexo を思い出すも Node.js をはじめから設定する必要があり、手始めに初期設定をメモします。 参考サイトMacにnodebrew（node.js, npm）をインストールする手順Qiita Markdown 書き方 まとめ所要時間3分!? Github PagesとHEXOで爆速ブログ構築してみよう！ 手順nvm のインストールgit clone git://github.com/creationix/nvm.git ~/.nvmsource ~/.nvm/nvm.sh nvm をターミナル起動時に有効にするnode -vv0.12.7nvm alias default v0.12.7default -&gt; v0.12.7vi ~/.zprofile if [[ -s ~/.nvm/nvm.sh ]];then source ~/.nvm/nvm.shfi source ~/.zprofile Hexo をインストールnpm install -g hexo 公開用の設定等は過去に実施していたようなので割愛liginc さんの元ネタの _config.yml の type は github でなく git でうまくいった ＊＊＊2017/08/01追記＊＊＊repository 指定先も変更Hexo でひさびさに deploy したらパーミッションエラー 記事の作成hexo new &#39;新規ページタイトル&#39; vi source/_posts/新規ページタイトル.md 新規記事のデプロイhexo d -g 反映しないときはキャッシュ消去hexo clean 以上","categories":[{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://www.fascinatedwithtofu.com/tags/hexo/"},{"name":"git","slug":"git","permalink":"http://www.fascinatedwithtofu.com/tags/git/"}]},{"title":"Hello World","slug":"hello-world","date":"2015-01-14T06:29:26.000Z","updated":"2023-01-16T07:30:26.850Z","comments":true,"path":"2015/01/14/hello-world/","link":"","permalink":"http://www.fascinatedwithtofu.com/2015/01/14/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new &quot;My New Post&quot; More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment","categories":[{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://www.fascinatedwithtofu.com/tags/hexo/"}]}],"categories":[{"name":"Music","slug":"Music","permalink":"http://www.fascinatedwithtofu.com/categories/Music/"},{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/categories/IT/"},{"name":"Other","slug":"Other","permalink":"http://www.fascinatedwithtofu.com/categories/Other/"},{"name":"Book","slug":"Book","permalink":"http://www.fascinatedwithtofu.com/categories/Book/"}],"tags":[{"name":"musicxml","slug":"musicxml","permalink":"http://www.fascinatedwithtofu.com/tags/musicxml/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://www.fascinatedwithtofu.com/tags/Ubuntu/"},{"name":"Game","slug":"Game","permalink":"http://www.fascinatedwithtofu.com/tags/Game/"},{"name":"hexo","slug":"hexo","permalink":"http://www.fascinatedwithtofu.com/tags/hexo/"},{"name":"git","slug":"git","permalink":"http://www.fascinatedwithtofu.com/tags/git/"},{"name":"domain","slug":"domain","permalink":"http://www.fascinatedwithtofu.com/tags/domain/"},{"name":"speedtest-cli","slug":"speedtest-cli","permalink":"http://www.fascinatedwithtofu.com/tags/speedtest-cli/"},{"name":"live","slug":"live","permalink":"http://www.fascinatedwithtofu.com/tags/live/"},{"name":"essay","slug":"essay","permalink":"http://www.fascinatedwithtofu.com/tags/essay/"},{"name":"scraping","slug":"scraping","permalink":"http://www.fascinatedwithtofu.com/tags/scraping/"},{"name":"slack","slug":"slack","permalink":"http://www.fascinatedwithtofu.com/tags/slack/"},{"name":"gas","slug":"gas","permalink":"http://www.fascinatedwithtofu.com/tags/gas/"},{"name":"movie","slug":"movie","permalink":"http://www.fascinatedwithtofu.com/tags/movie/"},{"name":"money","slug":"money","permalink":"http://www.fascinatedwithtofu.com/tags/money/"},{"name":"squid","slug":"squid","permalink":"http://www.fascinatedwithtofu.com/tags/squid/"},{"name":"apple","slug":"apple","permalink":"http://www.fascinatedwithtofu.com/tags/apple/"},{"name":"IoT","slug":"IoT","permalink":"http://www.fascinatedwithtofu.com/tags/IoT/"},{"name":"security","slug":"security","permalink":"http://www.fascinatedwithtofu.com/tags/security/"},{"name":"blog","slug":"blog","permalink":"http://www.fascinatedwithtofu.com/tags/blog/"},{"name":"apple affiliate","slug":"apple-affiliate","permalink":"http://www.fascinatedwithtofu.com/tags/apple-affiliate/"},{"name":"sauna","slug":"sauna","permalink":"http://www.fascinatedwithtofu.com/tags/sauna/"},{"name":"elastic","slug":"elastic","permalink":"http://www.fascinatedwithtofu.com/tags/elastic/"},{"name":"elk","slug":"elk","permalink":"http://www.fascinatedwithtofu.com/tags/elk/"},{"name":"logstash","slug":"logstash","permalink":"http://www.fascinatedwithtofu.com/tags/logstash/"},{"name":"kibana","slug":"kibana","permalink":"http://www.fascinatedwithtofu.com/tags/kibana/"},{"name":"netflow","slug":"netflow","permalink":"http://www.fascinatedwithtofu.com/tags/netflow/"},{"name":"alpine","slug":"alpine","permalink":"http://www.fascinatedwithtofu.com/tags/alpine/"},{"name":"docker","slug":"docker","permalink":"http://www.fascinatedwithtofu.com/tags/docker/"},{"name":"photon","slug":"photon","permalink":"http://www.fascinatedwithtofu.com/tags/photon/"},{"name":"amazon associate","slug":"amazon-associate","permalink":"http://www.fascinatedwithtofu.com/tags/amazon-associate/"},{"name":"IT","slug":"IT","permalink":"http://www.fascinatedwithtofu.com/tags/IT/"},{"name":"google adsense","slug":"google-adsense","permalink":"http://www.fascinatedwithtofu.com/tags/google-adsense/"},{"name":"ruby","slug":"ruby","permalink":"http://www.fascinatedwithtofu.com/tags/ruby/"},{"name":"chef","slug":"chef","permalink":"http://www.fascinatedwithtofu.com/tags/chef/"},{"name":"vagrant","slug":"vagrant","permalink":"http://www.fascinatedwithtofu.com/tags/vagrant/"}]}